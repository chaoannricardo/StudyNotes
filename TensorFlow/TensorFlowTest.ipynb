{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow & Mnist dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement \"load_mnist\" function:\n",
    "\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    " \n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path, \n",
    "                               '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, \n",
    "                               '%s-images-idx3-ubyte' % kind)\n",
    "        \n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', \n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, \n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", \n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, \n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    " \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, columns: 784\n",
      "Rows: 10000, columns: 784\n",
      "Training:  (50000, 784) (50000,)\n",
      "Training:  (10000, 784) (10000,)\n",
      "Training:  (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#### Loading data from Mnist dataset\n",
    "X_data, y_data = load_mnist('./mnist', kind='train')\n",
    "print('Rows: %d, columns: %d' % (X_data.shape[0], X_data.shape[1]))\n",
    "\n",
    "X_test, y_test = load_mnist('./mnist', kind='t10k')\n",
    "print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))\n",
    "\n",
    "#### Split training, validation data\n",
    "X_train, y_train = X_data[:50000, :], y_data[:50000]\n",
    "X_valid, y_valid = X_data[50000:, :], y_data[50000:]\n",
    "print('Training: ', X_train.shape, y_train.shape)\n",
    "print('Training: ', X_valid.shape, y_valid.shape)\n",
    "print('Training: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 迭代小批數據的函數\n",
    "def batch_generator(X, y, batch_size=64, shuffle=False, random_seed=None):\n",
    "    \n",
    "    idx = np.arange(y.shape[0])\n",
    "    \n",
    "    if shuffle:\n",
    "            rng = np.random.RandomState(random_seed)\n",
    "            rng.shuffle(idx)\n",
    "            X = X[idx]\n",
    "            y = y[idx]\n",
    "            \n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield (X[i:i+batch_size, :], y[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_valid_centered = (X_valid - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建構\"包裝函數\"：建構\"卷積層\"完成必要工作，包括：定義加權、偏誤。初始化後並將使用tf.nn.conv2d函數進行卷積運算\n",
    "# 有四個必要的參數：\n",
    "    # input_tensor: \"卷積層\"的輸入張量\n",
    "    # name: 用來限定範圍的\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def conv_layer(input_tensor, name, kernal_size, n_output_channels, padding_mode='SAME', strides=(1,1,1,1)):\n",
    "    with tf.variable_scope(name):\n",
    "        ## get n_input_channels:\n",
    "        ## input tensor shape:\n",
    "        ## [batch x width x height x channels-in]\n",
    "        input_shape = input_tensor.get_shape().as_list()\n",
    "        n_input_channels = input_shape[-1]\n",
    "        \n",
    "        weights_shape = list(kernak_size) + \\\n",
    "        [n_input_channels, n_output_channels]\n",
    "        \n",
    "        weights = tf.get_variable(name = '_weights ',\n",
    "                                 shape = weights_shape)\n",
    "        \n",
    "        print(weights)\n",
    "        \n",
    "        biases = tf.get_variable(name = '_biases',\n",
    "                                initializer=tf.zeros(\n",
    "                                shape=[n_output_channels]))\n",
    "        \n",
    "        print(biases)\n",
    "        \n",
    "        conv = tf.nn.conv2d(input=input_tensor,\n",
    "                           filter=weights,\n",
    "                           strides=strides,\n",
    "                           padding=padding_mode)\n",
    "        \n",
    "        print(conv)\n",
    "        \n",
    "        conv = tf.nn.bias_add(conv, biases, name='net_pre-activation')\n",
    "        \n",
    "        print(conv)\n",
    "        \n",
    "        conv = tf.nn.relu(conv, name = 'activation')\n",
    "        \n",
    "        return conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
