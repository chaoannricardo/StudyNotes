{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reference:\n",
    "    https://github.com/yeephycho/tensorflow_input_image_by_tfrecord/tree/master/src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tfrecord by image dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    https://github.com/yeephycho/tensorflow_input_image_by_tfrecord/blob/master/src/build_image_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to ./\n",
      "Determining list of input files and labels from ./OM_validation.\n",
      "Found 600 JPEG files across 2 labels inside ./OM_validation.\n",
      "Launching 2 threads for spacings: [[0, 300], [300, 600]]\n",
      "2019-07-19 16:43:26.218521 [thread 0]: Wrote 0 images to 300 shards.\n",
      "2019-07-19 16:43:26.224521 [thread 1]: Wrote 0 images to 300 shards.\n",
      "2019-07-19 16:43:27.236521: Finished writing all 600 images in data set.\n",
      "Determining list of input files and labels from ./OM_train.\n",
      "Found 1548 JPEG files across 2 labels inside ./OM_train.\n",
      "Launching 2 threads for spacings: [[0, 774], [774, 1548]]\n",
      "2019-07-19 16:43:43.238521 [thread 1]: Wrote 774 images to ./train-00001-of-00002.tfrecord\n",
      "2019-07-19 16:43:43.260521 [thread 1]: Wrote 774 images to 774 shards.\n",
      "2019-07-19 16:43:43.463521 [thread 0]: Wrote 774 images to ./train-00000-of-00002.tfrecord\n",
      "2019-07-19 16:43:43.477521 [thread 0]: Wrote 774 images to 774 shards.\n",
      "2019-07-19 16:43:44.240521: Finished writing all 1548 images in data set.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Converts image data to TFRecords file format with Example protos.\n",
    "The image data set is expected to reside in JPEG files located in the\n",
    "following directory structure.\n",
    "  data_dir/label_0/image0.jpeg\n",
    "  data_dir/label_0/image1.jpg\n",
    "  ...\n",
    "  data_dir/label_1/weird-image.jpeg\n",
    "  data_dir/label_1/my-image.jpeg\n",
    "  ...\n",
    "where the sub-directory is the unique label associated with these images.\n",
    "This TensorFlow script converts the training and evaluation data into\n",
    "a sharded data set consisting of TFRecord files\n",
    "  train_directory/train-00000-of-01024\n",
    "  train_directory/train-00001-of-01024\n",
    "  ...\n",
    "  train_directory/train-00127-of-01024\n",
    "and\n",
    "  validation_directory/validation-00000-of-00128\n",
    "  validation_directory/validation-00001-of-00128\n",
    "  ...\n",
    "  validation_directory/validation-00127-of-00128\n",
    "where we have selected 1024 and 128 shards for each data set. Each record\n",
    "within the TFRecord file is a serialized Example proto. The Example proto\n",
    "contains the following fields:\n",
    "  image/encoded: string containing JPEG encoded image in RGB colorspace\n",
    "  image/height: integer, image height in pixels\n",
    "  image/width: integer, image width in pixels\n",
    "  image/colorspace: string, specifying the colorspace, always 'RGB'\n",
    "  image/channels: integer, specifying the number of channels, always 3\n",
    "  image/format: string, specifying the format, always'JPEG'\n",
    "  image/filename: string containing the basename of the image file\n",
    "            e.g. 'n01440764_10026.JPEG' or 'ILSVRC2012_val_00000293.JPEG'\n",
    "  image/class/label: integer specifying the index in a classification layer.\n",
    "    The label ranges from [0, num_labels] where 0 is unused and left as\n",
    "    the background class.\n",
    "  image/class/text: string specifying the human-readable version of the label\n",
    "    e.g. 'dog'\n",
    "If you data set involves bounding boxes, please look at build_imagenet_data.py.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_directory', './OM_train',\n",
    "                           'Training data directory')\n",
    "tf.app.flags.DEFINE_string('validation_directory', './OM_validation',\n",
    "                           'Validation data directory')\n",
    "tf.app.flags.DEFINE_string('output_directory', './',\n",
    "                           'Output data directory')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('train_shards', 2,\n",
    "                            'Number of shards in training TFRecord files.')\n",
    "tf.app.flags.DEFINE_integer('validation_shards', 0,\n",
    "                            'Number of shards in validation TFRecord files.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_threads', 2,\n",
    "                            'Number of threads to preprocess the images.')\n",
    "\n",
    "# The labels file contains a list of valid labels are held in this file.\n",
    "# Assumes that the file contains entries as such:\n",
    "#   dog\n",
    "#   cat\n",
    "#   flower\n",
    "# where each line corresponds to a label. We map each label contained in\n",
    "# the file to an integer corresponding to the line number starting from 0.\n",
    "tf.app.flags.DEFINE_string('labels_file', './label.txt', 'Labels file')\n",
    "\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
    "  if not isinstance(value, list):\n",
    "    value = [value]\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _convert_to_example(filename, image_buffer, label, text, height, width):\n",
    "  \"\"\"Build an Example proto for an example.\n",
    "  Args:\n",
    "    filename: string, path to an image file, e.g., '/path/to/example.JPG'\n",
    "    image_buffer: string, JPEG encoding of RGB image\n",
    "    label: integer, identifier for the ground truth for the network\n",
    "    text: string, unique human-readable, e.g. 'dog'\n",
    "    height: integer, image height in pixels\n",
    "    width: integer, image width in pixels\n",
    "  Returns:\n",
    "    Example proto\n",
    "  \"\"\"\n",
    "\n",
    "  colorspace = 'RGB'\n",
    "  channels = 3\n",
    "  image_format = 'JPEG'\n",
    "\n",
    "  example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': _int64_feature(height),\n",
    "      'image/width': _int64_feature(width),\n",
    "      'image/colorspace': _bytes_feature(tf.compat.as_bytes(colorspace)),\n",
    "      'image/channels': _int64_feature(channels),\n",
    "      'image/class/label': _int64_feature(label),\n",
    "      'image/class/text': _bytes_feature(tf.compat.as_bytes(text)),\n",
    "      'image/format': _bytes_feature(tf.compat.as_bytes(image_format)),\n",
    "      'image/filename': _bytes_feature(tf.compat.as_bytes(os.path.basename(filename))),\n",
    "      'image/encoded': _bytes_feature(tf.compat.as_bytes(image_buffer))}))\n",
    "  return example\n",
    "\n",
    "\n",
    "class ImageCoder(object):\n",
    "  \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    # Create a single Session to run all image coding calls.\n",
    "    self._sess = tf.Session()\n",
    "\n",
    "    # Initializes function that converts PNG to JPEG data.\n",
    "    self._png_data = tf.placeholder(dtype=tf.string)\n",
    "    image = tf.image.decode_png(self._png_data, channels=3)\n",
    "    self._png_to_jpeg = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "    # Initializes function that decodes RGB JPEG data.\n",
    "    self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n",
    "    self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n",
    "\n",
    "  def png_to_jpeg(self, image_data):\n",
    "    return self._sess.run(self._png_to_jpeg,\n",
    "                          feed_dict={self._png_data: image_data})\n",
    "\n",
    "  def decode_jpeg(self, image_data):\n",
    "    image = self._sess.run(self._decode_jpeg,\n",
    "                           feed_dict={self._decode_jpeg_data: image_data})\n",
    "    assert len(image.shape) == 3\n",
    "    assert image.shape[2] == 3\n",
    "    return image\n",
    "\n",
    "\n",
    "def _is_png(filename):\n",
    "  \"\"\"Determine if a file contains a PNG format image.\n",
    "  Args:\n",
    "    filename: string, path of the image file.\n",
    "  Returns:\n",
    "    boolean indicating if the image is a PNG.\n",
    "  \"\"\"\n",
    "  return '.png' in filename\n",
    "\n",
    "\n",
    "def _process_image(filename, coder):\n",
    "  \"\"\"Process a single image file.\n",
    "  Args:\n",
    "    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "  Returns:\n",
    "    image_buffer: string, JPEG encoding of RGB image.\n",
    "    height: integer, image height in pixels.\n",
    "    width: integer, image width in pixels.\n",
    "  \"\"\"\n",
    "  # Read the image file.\n",
    "  with tf.gfile.FastGFile(filename, 'rb') as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "  # Convert any PNG to JPEG's for consistency.\n",
    "  if _is_png(filename):\n",
    "    print('Converting PNG to JPEG for %s' % filename)\n",
    "    image_data = coder.png_to_jpeg(image_data)\n",
    "\n",
    "  # Decode the RGB JPEG.\n",
    "  image = coder.decode_jpeg(image_data)\n",
    "\n",
    "  # Check that image converted to RGB\n",
    "  assert len(image.shape) == 3\n",
    "  height = image.shape[0]\n",
    "  width = image.shape[1]\n",
    "  assert image.shape[2] == 3\n",
    "\n",
    "  return image_data, height, width\n",
    "\n",
    "\n",
    "def _process_image_files_batch(coder, thread_index, ranges, name, filenames,\n",
    "                               texts, labels, num_shards):\n",
    "  \"\"\"Processes and saves list of images as TFRecord in 1 thread.\n",
    "  Args:\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "    thread_index: integer, unique batch to run index is within [0, len(ranges)).\n",
    "    ranges: list of pairs of integers specifying ranges of each batches to\n",
    "      analyze in parallel.\n",
    "    name: string, unique identifier specifying the data set\n",
    "    filenames: list of strings; each string is a path to an image file\n",
    "    texts: list of strings; each string is human readable, e.g. 'dog'\n",
    "    labels: list of integer; each integer identifies the ground truth\n",
    "    num_shards: integer number of shards for this data set.\n",
    "  \"\"\"\n",
    "  # Each thread produces N shards where N = int(num_shards / num_threads).\n",
    "  # For instance, if num_shards = 128, and the num_threads = 2, then the first\n",
    "  # thread would produce shards [0, 64).\n",
    "  num_threads = len(ranges)\n",
    "  assert not num_shards % num_threads\n",
    "  num_shards_per_batch = int(num_shards / num_threads)\n",
    "\n",
    "  shard_ranges = np.linspace(ranges[thread_index][0],\n",
    "                             ranges[thread_index][1],\n",
    "                             num_shards_per_batch + 1).astype(int)\n",
    "  num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n",
    "\n",
    "  counter = 0\n",
    "  for s in range(num_shards_per_batch):\n",
    "    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n",
    "    shard = thread_index * num_shards_per_batch + s\n",
    "    output_filename = '%s-%.5d-of-%.5d.tfrecord' % (name, shard, num_shards)\n",
    "    output_file = os.path.join(FLAGS.output_directory, output_filename)\n",
    "    writer = tf.python_io.TFRecordWriter(output_file)\n",
    "\n",
    "    shard_counter = 0\n",
    "    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n",
    "    for i in files_in_shard:\n",
    "      filename = filenames[i]\n",
    "      label = labels[i]\n",
    "      text = texts[i]\n",
    "\n",
    "      image_buffer, height, width = _process_image(filename, coder)\n",
    "\n",
    "      example = _convert_to_example(filename, image_buffer, label,\n",
    "                                    text, height, width)\n",
    "      writer.write(example.SerializeToString())\n",
    "      shard_counter += 1\n",
    "      counter += 1\n",
    "\n",
    "      if not counter % 1000:\n",
    "        print('%s [thread %d]: Processed %d of %d images in thread batch.' %\n",
    "              (datetime.now(), thread_index, counter, num_files_in_thread))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    writer.close()\n",
    "    print('%s [thread %d]: Wrote %d images to %s' %\n",
    "          (datetime.now(), thread_index, shard_counter, output_file))\n",
    "    sys.stdout.flush()\n",
    "    shard_counter = 0\n",
    "  print('%s [thread %d]: Wrote %d images to %d shards.' %\n",
    "        (datetime.now(), thread_index, counter, num_files_in_thread))\n",
    "  sys.stdout.flush()\n",
    "\n",
    "\n",
    "def _process_image_files(name, filenames, texts, labels, num_shards):\n",
    "  \"\"\"Process and save list of images as TFRecord of Example protos.\n",
    "  Args:\n",
    "    name: string, unique identifier specifying the data set\n",
    "    filenames: list of strings; each string is a path to an image file\n",
    "    texts: list of strings; each string is human readable, e.g. 'dog'\n",
    "    labels: list of integer; each integer identifies the ground truth\n",
    "    num_shards: integer number of shards for this data set.\n",
    "  \"\"\"\n",
    "  assert len(filenames) == len(texts)\n",
    "  assert len(filenames) == len(labels)\n",
    "\n",
    "  # Break all images into batches with a [ranges[i][0], ranges[i][1]].\n",
    "  spacing = np.linspace(0, len(filenames), FLAGS.num_threads + 1).astype(np.int)\n",
    "  ranges = []\n",
    "  for i in range(len(spacing) - 1):\n",
    "    ranges.append([spacing[i], spacing[i+1]])\n",
    "\n",
    "  # Launch a thread for each batch.\n",
    "  print('Launching %d threads for spacings: %s' % (FLAGS.num_threads, ranges))\n",
    "  sys.stdout.flush()\n",
    "\n",
    "  # Create a mechanism for monitoring when all threads are finished.\n",
    "  coord = tf.train.Coordinator()\n",
    "\n",
    "  # Create a generic TensorFlow-based utility for converting all image codings.\n",
    "  coder = ImageCoder()\n",
    "\n",
    "  threads = []\n",
    "  for thread_index in range(len(ranges)):\n",
    "    args = (coder, thread_index, ranges, name, filenames,\n",
    "            texts, labels, num_shards)\n",
    "    t = threading.Thread(target=_process_image_files_batch, args=args)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "  # Wait for all the threads to terminate.\n",
    "  coord.join(threads)\n",
    "  print('%s: Finished writing all %d images in data set.' %\n",
    "        (datetime.now(), len(filenames)))\n",
    "  sys.stdout.flush()\n",
    "\n",
    "\n",
    "def _find_image_files(data_dir, labels_file):\n",
    "  \"\"\"Build a list of all images files and labels in the data set.\n",
    "  Args:\n",
    "    data_dir: string, path to the root directory of images.\n",
    "      Assumes that the image data set resides in JPEG files located in\n",
    "      the following directory structure.\n",
    "        data_dir/dog/another-image.JPEG\n",
    "        data_dir/dog/my-image.jpg\n",
    "      where 'dog' is the label associated with these images.\n",
    "    labels_file: string, path to the labels file.\n",
    "      The list of valid labels are held in this file. Assumes that the file\n",
    "      contains entries as such:\n",
    "        dog\n",
    "        cat\n",
    "        flower\n",
    "      where each line corresponds to a label. We map each label contained in\n",
    "      the file to an integer starting with the integer 0 corresponding to the\n",
    "      label contained in the first line.\n",
    "  Returns:\n",
    "    filenames: list of strings; each string is a path to an image file.\n",
    "    texts: list of strings; each string is the class, e.g. 'dog'\n",
    "    labels: list of integer; each integer identifies the ground truth.\n",
    "  \"\"\"\n",
    "  print('Determining list of input files and labels from %s.' % data_dir)\n",
    "  unique_labels = [l.strip() for l in tf.gfile.FastGFile(\n",
    "      labels_file, 'r').readlines()]\n",
    "\n",
    "  labels = []\n",
    "  filenames = []\n",
    "  texts = []\n",
    "\n",
    "  # Leave label index 0 empty as a background class.\n",
    "  label_index = 1\n",
    "\n",
    "  # Construct the list of JPEG files and labels.\n",
    "  for text in unique_labels:\n",
    "    jpeg_file_path = '%s/%s/*' % (data_dir, text)\n",
    "    matching_files = tf.gfile.Glob(jpeg_file_path)\n",
    "\n",
    "    labels.extend([label_index] * len(matching_files))\n",
    "    texts.extend([text] * len(matching_files))\n",
    "    filenames.extend(matching_files)\n",
    "\n",
    "    if not label_index % 100:\n",
    "      print('Finished finding files in %d of %d classes.' % (\n",
    "          label_index, len(labels)))\n",
    "    label_index += 1\n",
    "\n",
    "  # Shuffle the ordering of all image files in order to guarantee\n",
    "  # random ordering of the images with respect to label in the\n",
    "  # saved TFRecord files. Make the randomization repeatable.\n",
    "  shuffled_index = list(range(len(filenames)))\n",
    "  random.seed(12345)\n",
    "  random.shuffle(shuffled_index)\n",
    "\n",
    "  filenames = [filenames[i] for i in shuffled_index]\n",
    "  texts = [texts[i] for i in shuffled_index]\n",
    "  labels = [labels[i] for i in shuffled_index]\n",
    "\n",
    "  print('Found %d JPEG files across %d labels inside %s.' %\n",
    "        (len(filenames), len(unique_labels), data_dir))\n",
    "  return filenames, texts, labels\n",
    "\n",
    "\n",
    "def _process_dataset(name, directory, num_shards, labels_file):\n",
    "  \"\"\"Process a complete data set and save it as a TFRecord.\n",
    "  Args:\n",
    "    name: string, unique identifier specifying the data set.\n",
    "    directory: string, root path to the data set.\n",
    "    num_shards: integer number of shards for this data set.\n",
    "    labels_file: string, path to the labels file.\n",
    "  \"\"\"\n",
    "  filenames, texts, labels = _find_image_files(directory, labels_file)\n",
    "  _process_image_files(name, filenames, texts, labels, num_shards)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  assert not FLAGS.train_shards % FLAGS.num_threads, (\n",
    "      'Please make the FLAGS.num_threads commensurate with FLAGS.train_shards')\n",
    "  assert not FLAGS.validation_shards % FLAGS.num_threads, (\n",
    "      'Please make the FLAGS.num_threads commensurate with '\n",
    "      'FLAGS.validation_shards')\n",
    "  print('Saving results to %s' % FLAGS.output_directory)\n",
    "\n",
    "  # Run it!\n",
    "  _process_dataset('validation', FLAGS.validation_directory,\n",
    "                   FLAGS.validation_shards, FLAGS.labels_file)\n",
    "  _process_dataset('train', FLAGS.train_directory,\n",
    "                   FLAGS.train_shards, FLAGS.labels_file)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
