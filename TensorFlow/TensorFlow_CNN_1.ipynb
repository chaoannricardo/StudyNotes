{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python working directory has now been changed to C:\\Users\\1907075\\Project\\OM\n",
      "Program would then continue.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Change working directory into OM directory\n",
    "'''\n",
    "\n",
    "import os\n",
    "while True:\n",
    "    try:\n",
    "        os.chdir('./OM')\n",
    "    except BaseException:\n",
    "        pathnow = os.getcwd()\n",
    "        print('Working directory now:', pathnow)\n",
    "        print(\"Have you created 'TempData' directory within python working directory? If not, create it.\")\n",
    "        print(\"================= The program has been terminated =================.\")\n",
    "        print(\"Reminder: Try again after fulfilling the requirements.\")\n",
    "        break\n",
    "    else:\n",
    "        pathnow = os.getcwd()\n",
    "        print(\"Python working directory has now been changed to\", pathnow)\n",
    "        print('Program would then continue.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Image Dataset for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to ./\n",
      "Determining list of input files and labels from ./.\n",
      "Found 7002 JPEG files across 2 labels inside ./.\n",
      "Launching 2 threads for spacings: [[0, 3501], [3501, 7002]]\n",
      "2019-07-18 14:05:20.692993 [thread 0]: Wrote 0 images to 3501 shards.2019-07-18 14:05:20.698993 [thread 1]: Wrote 0 images to 3501 shards.\n",
      "\n",
      "2019-07-18 14:05:21.711993: Finished writing all 7002 images in data set.\n",
      "Determining list of input files and labels from ./.\n",
      "Found 7002 JPEG files across 2 labels inside ./.\n",
      "Launching 2 threads for spacings: [[0, 3501], [3501, 7002]]\n",
      "2019-07-18 14:05:41.089993 [thread 0]: Processed 1000 of 3501 images in thread batch.\n",
      "2019-07-18 14:05:41.222993 [thread 1]: Processed 1000 of 3501 images in thread batch.\n",
      "2019-07-18 14:05:58.886993 [thread 0]: Processed 2000 of 3501 images in thread batch.\n",
      "2019-07-18 14:05:59.261993 [thread 1]: Processed 2000 of 3501 images in thread batch.\n",
      "2019-07-18 14:06:17.670993 [thread 0]: Processed 3000 of 3501 images in thread batch.\n",
      "2019-07-18 14:06:17.943993 [thread 1]: Processed 3000 of 3501 images in thread batch.\n",
      "2019-07-18 14:06:22.093993 [thread 0]: Wrote 3501 images to ./train-00000-of-00002.tfrecord\n",
      "2019-07-18 14:06:22.096993 [thread 0]: Wrote 3501 images to 3501 shards.\n",
      "2019-07-18 14:06:22.687993 [thread 1]: Wrote 3501 images to ./train-00001-of-00002.tfrecord\n",
      "2019-07-18 14:06:22.689993 [thread 1]: Wrote 3501 images to 3501 shards.\n",
      "2019-07-18 14:06:23.098993: Finished writing all 7002 images in data set.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This Program would build your images inside your directory into tfrecord files.\n",
    "[Procedure Guide]\n",
    "# Store your images into directories named after the label. (under your working directory.)\n",
    "# Create label.txt file which consist of the names of the labels. (under your working directory)\n",
    "[Guide Reference] https://yeephycho.github.io/2016/08/15/image-data-in-tensorflow/\n",
    "[Code Reference] https://github.com/yeephycho/tensorflow_input_image_by_tfrecord/blob/master/src/build_image_data.py\n",
    "'''\n",
    "\n",
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Converts image data to TFRecords file format with Example protos.\n",
    "The image data set is expected to reside in JPEG files located in the\n",
    "following directory structure.\n",
    "  data_dir/label_0/image0.jpeg\n",
    "  data_dir/label_0/image1.jpg\n",
    "  ...\n",
    "  data_dir/label_1/weird-image.jpeg\n",
    "  data_dir/label_1/my-image.jpeg\n",
    "  ...\n",
    "where the sub-directory is the unique label associated with these images.\n",
    "This TensorFlow script converts the training and evaluation data into\n",
    "a sharded data set consisting of TFRecord files\n",
    "  train_directory/train-00000-of-01024\n",
    "  train_directory/train-00001-of-01024\n",
    "  ...\n",
    "  train_directory/train-00127-of-01024\n",
    "and\n",
    "  validation_directory/validation-00000-of-00128\n",
    "  validation_directory/validation-00001-of-00128\n",
    "  ...\n",
    "  validation_directory/validation-00127-of-00128\n",
    "where we have selected 1024 and 128 shards for each data set. Each record\n",
    "within the TFRecord file is a serialized Example proto. The Example proto\n",
    "contains the following fields:\n",
    "  image/encoded: string containing JPEG encoded image in RGB colorspace\n",
    "  image/height: integer, image height in pixels\n",
    "  image/width: integer, image width in pixels\n",
    "  image/colorspace: string, specifying the colorspace, always 'RGB'\n",
    "  image/channels: integer, specifying the number of channels, always 3\n",
    "  image/format: string, specifying the format, always'JPEG'\n",
    "  image/filename: string containing the basename of the image file\n",
    "            e.g. 'n01440764_10026.JPEG' or 'ILSVRC2012_val_00000293.JPEG'\n",
    "  image/class/label: integer specifying the index in a classification layer.\n",
    "    The label ranges from [0, num_labels] where 0 is unused and left as\n",
    "    the background class.\n",
    "  image/class/text: string specifying the human-readable version of the label\n",
    "    e.g. 'dog'\n",
    "If you data set involves bounding boxes, please look at build_imagenet_data.py.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_directory', './',\n",
    "                           'Training data directory')\n",
    "tf.app.flags.DEFINE_string('validation_directory', './',\n",
    "                           'Validation data directory')\n",
    "tf.app.flags.DEFINE_string('output_directory', './',\n",
    "                           'Output data directory')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('train_shards', 2,\n",
    "                            'Number of shards in training TFRecord files.')\n",
    "tf.app.flags.DEFINE_integer('validation_shards', 0,\n",
    "                            'Number of shards in validation TFRecord files.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_threads', 2,\n",
    "                            'Number of threads to preprocess the images.')\n",
    "\n",
    "# The labels file contains a list of valid labels are held in this file.\n",
    "# Assumes that the file contains entries as such:\n",
    "#   dog\n",
    "#   cat\n",
    "#   flower\n",
    "# where each line corresponds to a label. We map each label contained in\n",
    "# the file to an integer corresponding to the line number starting from 0.\n",
    "tf.app.flags.DEFINE_string('labels_file', './label.txt', 'Labels file')\n",
    "\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
    "  if not isinstance(value, list):\n",
    "    value = [value]\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _convert_to_example(filename, image_buffer, label, text, height, width):\n",
    "  \"\"\"Build an Example proto for an example.\n",
    "  Args:\n",
    "    filename: string, path to an image file, e.g., '/path/to/example.JPG'\n",
    "    image_buffer: string, JPEG encoding of RGB image\n",
    "    label: integer, identifier for the ground truth for the network\n",
    "    text: string, unique human-readable, e.g. 'dog'\n",
    "    height: integer, image height in pixels\n",
    "    width: integer, image width in pixels\n",
    "  Returns:\n",
    "    Example proto\n",
    "  \"\"\"\n",
    "\n",
    "  colorspace = 'RGB'\n",
    "  channels = 3\n",
    "  image_format = 'JPEG'\n",
    "\n",
    "  example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': _int64_feature(height),\n",
    "      'image/width': _int64_feature(width),\n",
    "      'image/colorspace': _bytes_feature(tf.compat.as_bytes(colorspace)),\n",
    "      'image/channels': _int64_feature(channels),\n",
    "      'image/class/label': _int64_feature(label),\n",
    "      'image/class/text': _bytes_feature(tf.compat.as_bytes(text)),\n",
    "      'image/format': _bytes_feature(tf.compat.as_bytes(image_format)),\n",
    "      'image/filename': _bytes_feature(tf.compat.as_bytes(os.path.basename(filename))),\n",
    "      'image/encoded': _bytes_feature(tf.compat.as_bytes(image_buffer))}))\n",
    "  return example\n",
    "\n",
    "\n",
    "class ImageCoder(object):\n",
    "  \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    # Create a single Session to run all image coding calls.\n",
    "    self._sess = tf.Session()\n",
    "\n",
    "    # Initializes function that converts PNG to JPEG data.\n",
    "    self._png_data = tf.placeholder(dtype=tf.string)\n",
    "    image = tf.image.decode_png(self._png_data, channels=3)\n",
    "    self._png_to_jpeg = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "    # Initializes function that decodes RGB JPEG data.\n",
    "    self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n",
    "    self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n",
    "\n",
    "  def png_to_jpeg(self, image_data):\n",
    "    return self._sess.run(self._png_to_jpeg,\n",
    "                          feed_dict={self._png_data: image_data})\n",
    "\n",
    "  def decode_jpeg(self, image_data):\n",
    "    image = self._sess.run(self._decode_jpeg,\n",
    "                           feed_dict={self._decode_jpeg_data: image_data})\n",
    "    assert len(image.shape) == 3\n",
    "    assert image.shape[2] == 3\n",
    "    return image\n",
    "\n",
    "\n",
    "def _is_png(filename):\n",
    "  \"\"\"Determine if a file contains a PNG format image.\n",
    "  Args:\n",
    "    filename: string, path of the image file.\n",
    "  Returns:\n",
    "    boolean indicating if the image is a PNG.\n",
    "  \"\"\"\n",
    "  return '.png' in filename\n",
    "\n",
    "\n",
    "def _process_image(filename, coder):\n",
    "  \"\"\"Process a single image file.\n",
    "  Args:\n",
    "    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "  Returns:\n",
    "    image_buffer: string, JPEG encoding of RGB image.\n",
    "    height: integer, image height in pixels.\n",
    "    width: integer, image width in pixels.\n",
    "  \"\"\"\n",
    "  # Read the image file.\n",
    "  with tf.gfile.FastGFile(filename, 'rb') as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "  # Convert any PNG to JPEG's for consistency.\n",
    "  if _is_png(filename):\n",
    "    print('Converting PNG to JPEG for %s' % filename)\n",
    "    image_data = coder.png_to_jpeg(image_data)\n",
    "\n",
    "  # Decode the RGB JPEG.\n",
    "  image = coder.decode_jpeg(image_data)\n",
    "\n",
    "  # Check that image converted to RGB\n",
    "  assert len(image.shape) == 3\n",
    "  height = image.shape[0]\n",
    "  width = image.shape[1]\n",
    "  assert image.shape[2] == 3\n",
    "\n",
    "  return image_data, height, width\n",
    "\n",
    "\n",
    "def _process_image_files_batch(coder, thread_index, ranges, name, filenames,\n",
    "                               texts, labels, num_shards):\n",
    "  \"\"\"Processes and saves list of images as TFRecord in 1 thread.\n",
    "  Args:\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "    thread_index: integer, unique batch to run index is within [0, len(ranges)).\n",
    "    ranges: list of pairs of integers specifying ranges of each batches to\n",
    "      analyze in parallel.\n",
    "    name: string, unique identifier specifying the data set\n",
    "    filenames: list of strings; each string is a path to an image file\n",
    "    texts: list of strings; each string is human readable, e.g. 'dog'\n",
    "    labels: list of integer; each integer identifies the ground truth\n",
    "    num_shards: integer number of shards for this data set.\n",
    "  \"\"\"\n",
    "  # Each thread produces N shards where N = int(num_shards / num_threads).\n",
    "  # For instance, if num_shards = 128, and the num_threads = 2, then the first\n",
    "  # thread would produce shards [0, 64).\n",
    "  num_threads = len(ranges)\n",
    "  assert not num_shards % num_threads\n",
    "  num_shards_per_batch = int(num_shards / num_threads)\n",
    "\n",
    "  shard_ranges = np.linspace(ranges[thread_index][0],\n",
    "                             ranges[thread_index][1],\n",
    "                             num_shards_per_batch + 1).astype(int)\n",
    "  num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n",
    "\n",
    "  counter = 0\n",
    "  for s in range(num_shards_per_batch):\n",
    "    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n",
    "    shard = thread_index * num_shards_per_batch + s\n",
    "    output_filename = '%s-%.5d-of-%.5d.tfrecord' % (name, shard, num_shards)\n",
    "    output_file = os.path.join(FLAGS.output_directory, output_filename)\n",
    "    writer = tf.python_io.TFRecordWriter(output_file)\n",
    "\n",
    "    shard_counter = 0\n",
    "    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n",
    "    for i in files_in_shard:\n",
    "      filename = filenames[i]\n",
    "      label = labels[i]\n",
    "      text = texts[i]\n",
    "\n",
    "      image_buffer, height, width = _process_image(filename, coder)\n",
    "\n",
    "      example = _convert_to_example(filename, image_buffer, label,\n",
    "                                    text, height, width)\n",
    "      writer.write(example.SerializeToString())\n",
    "      shard_counter += 1\n",
    "      counter += 1\n",
    "\n",
    "      if not counter % 1000:\n",
    "        print('%s [thread %d]: Processed %d of %d images in thread batch.' %\n",
    "              (datetime.now(), thread_index, counter, num_files_in_thread))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    writer.close()\n",
    "    print('%s [thread %d]: Wrote %d images to %s' %\n",
    "          (datetime.now(), thread_index, shard_counter, output_file))\n",
    "    sys.stdout.flush()\n",
    "    shard_counter = 0\n",
    "  print('%s [thread %d]: Wrote %d images to %d shards.' %\n",
    "        (datetime.now(), thread_index, counter, num_files_in_thread))\n",
    "  sys.stdout.flush()\n",
    "\n",
    "\n",
    "def _process_image_files(name, filenames, texts, labels, num_shards):\n",
    "  \"\"\"Process and save list of images as TFRecord of Example protos.\n",
    "  Args:\n",
    "    name: string, unique identifier specifying the data set\n",
    "    filenames: list of strings; each string is a path to an image file\n",
    "    texts: list of strings; each string is human readable, e.g. 'dog'\n",
    "    labels: list of integer; each integer identifies the ground truth\n",
    "    num_shards: integer number of shards for this data set.\n",
    "  \"\"\"\n",
    "  assert len(filenames) == len(texts)\n",
    "  assert len(filenames) == len(labels)\n",
    "\n",
    "  # Break all images into batches with a [ranges[i][0], ranges[i][1]].\n",
    "  spacing = np.linspace(0, len(filenames), FLAGS.num_threads + 1).astype(np.int)\n",
    "  ranges = []\n",
    "  for i in range(len(spacing) - 1):\n",
    "    ranges.append([spacing[i], spacing[i+1]])\n",
    "\n",
    "  # Launch a thread for each batch.\n",
    "  print('Launching %d threads for spacings: %s' % (FLAGS.num_threads, ranges))\n",
    "  sys.stdout.flush()\n",
    "\n",
    "  # Create a mechanism for monitoring when all threads are finished.\n",
    "  coord = tf.train.Coordinator()\n",
    "\n",
    "  # Create a generic TensorFlow-based utility for converting all image codings.\n",
    "  coder = ImageCoder()\n",
    "\n",
    "  threads = []\n",
    "  for thread_index in range(len(ranges)):\n",
    "    args = (coder, thread_index, ranges, name, filenames,\n",
    "            texts, labels, num_shards)\n",
    "    t = threading.Thread(target=_process_image_files_batch, args=args)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "  # Wait for all the threads to terminate.\n",
    "  coord.join(threads)\n",
    "  print('%s: Finished writing all %d images in data set.' %\n",
    "        (datetime.now(), len(filenames)))\n",
    "  sys.stdout.flush()\n",
    "\n",
    "\n",
    "def _find_image_files(data_dir, labels_file):\n",
    "  \"\"\"Build a list of all images files and labels in the data set.\n",
    "  Args:\n",
    "    data_dir: string, path to the root directory of images.\n",
    "      Assumes that the image data set resides in JPEG files located in\n",
    "      the following directory structure.\n",
    "        data_dir/dog/another-image.JPEG\n",
    "        data_dir/dog/my-image.jpg\n",
    "      where 'dog' is the label associated with these images.\n",
    "    labels_file: string, path to the labels file.\n",
    "      The list of valid labels are held in this file. Assumes that the file\n",
    "      contains entries as such:\n",
    "        dog\n",
    "        cat\n",
    "        flower\n",
    "      where each line corresponds to a label. We map each label contained in\n",
    "      the file to an integer starting with the integer 0 corresponding to the\n",
    "      label contained in the first line.\n",
    "  Returns:\n",
    "    filenames: list of strings; each string is a path to an image file.\n",
    "    texts: list of strings; each string is the class, e.g. 'dog'\n",
    "    labels: list of integer; each integer identifies the ground truth.\n",
    "  \"\"\"\n",
    "  print('Determining list of input files and labels from %s.' % data_dir)\n",
    "  unique_labels = [l.strip() for l in tf.gfile.FastGFile(\n",
    "      labels_file, 'r').readlines()]\n",
    "\n",
    "  labels = []\n",
    "  filenames = []\n",
    "  texts = []\n",
    "\n",
    "  # Leave label index 0 empty as a background class.\n",
    "  label_index = 1\n",
    "\n",
    "  # Construct the list of JPEG files and labels.\n",
    "  for text in unique_labels:\n",
    "    jpeg_file_path = '%s/%s/*' % (data_dir, text)\n",
    "    matching_files = tf.gfile.Glob(jpeg_file_path)\n",
    "\n",
    "    labels.extend([label_index] * len(matching_files))\n",
    "    texts.extend([text] * len(matching_files))\n",
    "    filenames.extend(matching_files)\n",
    "\n",
    "    if not label_index % 100:\n",
    "      print('Finished finding files in %d of %d classes.' % (\n",
    "          label_index, len(labels)))\n",
    "    label_index += 1\n",
    "\n",
    "  # Shuffle the ordering of all image files in order to guarantee\n",
    "  # random ordering of the images with respect to label in the\n",
    "  # saved TFRecord files. Make the randomization repeatable.\n",
    "  shuffled_index = list(range(len(filenames)))\n",
    "  random.seed(12345)\n",
    "  random.shuffle(shuffled_index)\n",
    "\n",
    "  filenames = [filenames[i] for i in shuffled_index]\n",
    "  texts = [texts[i] for i in shuffled_index]\n",
    "  labels = [labels[i] for i in shuffled_index]\n",
    "\n",
    "  print('Found %d JPEG files across %d labels inside %s.' %\n",
    "        (len(filenames), len(unique_labels), data_dir))\n",
    "  return filenames, texts, labels\n",
    "\n",
    "\n",
    "def _process_dataset(name, directory, num_shards, labels_file):\n",
    "  \"\"\"Process a complete data set and save it as a TFRecord.\n",
    "  Args:\n",
    "    name: string, unique identifier specifying the data set.\n",
    "    directory: string, root path to the data set.\n",
    "    num_shards: integer number of shards for this data set.\n",
    "    labels_file: string, path to the labels file.\n",
    "  \"\"\"\n",
    "  filenames, texts, labels = _find_image_files(directory, labels_file)\n",
    "  _process_image_files(name, filenames, texts, labels, num_shards)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  assert not FLAGS.train_shards % FLAGS.num_threads, (\n",
    "      'Please make the FLAGS.num_threads commensurate with FLAGS.train_shards')\n",
    "  assert not FLAGS.validation_shards % FLAGS.num_threads, (\n",
    "      'Please make the FLAGS.num_threads commensurate with '\n",
    "      'FLAGS.validation_shards')\n",
    "  print('Saving results to %s' % FLAGS.output_directory)\n",
    "\n",
    "  # Run it!\n",
    "  _process_dataset('validation', FLAGS.validation_directory,\n",
    "                   FLAGS.validation_shards, FLAGS.labels_file)\n",
    "  _process_dataset('train', FLAGS.train_directory,\n",
    "                   FLAGS.train_shards, FLAGS.labels_file)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The program will do the directory traversal to your current directory, \n",
    "list all the file names or folder names, and select all the files end with .tfrecord. \n",
    "Return the list of names of the tfrecord files.\n",
    "'''\n",
    "\n",
    "import os  # handle system path and filenames\n",
    "import tensorflow as tf  # import tensorflow as usual\n",
    "\n",
    "# define a function to list tfrecord files.\n",
    "def list_tfrecord_file(file_list):\n",
    "    tfrecord_list = []\n",
    "    for i in range(len(file_list)):\n",
    "        current_file_abs_path = os.path.abspath(file_list[i])\n",
    "        if current_file_abs_path.endswith(\".tfrecord\"):\n",
    "            tfrecord_list.append(current_file_abs_path)\n",
    "            print(\"Found %s successfully!\" % file_list[i])\n",
    "        else:\n",
    "            pass\n",
    "    return tfrecord_list\n",
    "\n",
    "# Traverse current directory\n",
    "def tfrecord_auto_traversal():\n",
    "    current_folder_filename_list = os.listdir(\"./\") # Change this PATH to traverse other directories if you want.\n",
    "    if current_folder_filename_list != None:\n",
    "        print(\"%s files were found under current folder. \" % len(current_folder_filename_list))\n",
    "        print(\"Please be noted that only files end with '*.tfrecord' will be load!\")\n",
    "        tfrecord_list = list_tfrecord_file(current_folder_filename_list)\n",
    "        if len(tfrecord_list) != 0:\n",
    "            for list_index in range(len(tfrecord_list)):\n",
    "                print(tfrecord_list[list_index])\n",
    "        else:\n",
    "            print(\"Cannot find any tfrecord files, please check the path.\")\n",
    "    return tfrecord_list\n",
    "\n",
    "def main():\n",
    "    tfrecord_list = tfrecord_auto_traversal()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 files were found under current folder. \n",
      "Please be noted that only files end with '*.tfrecord' will be load!\n",
      "Found train-00000-of-00002.tfrecord successfully!\n",
      "Found train-00001-of-00002.tfrecord successfully!\n",
      "C:\\Users\\1907075\\Project\\OM\\train-00000-of-00002.tfrecord\n",
      "C:\\Users\\1907075\\Project\\OM\\train-00001-of-00002.tfrecord\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Write cropped and resized image to the folder './resized_image'\n",
      "0 images in 7002 has finished!\n",
      "10 images in 7002 has finished!\n",
      "20 images in 7002 has finished!\n",
      "30 images in 7002 has finished!\n",
      "40 images in 7002 has finished!\n",
      "50 images in 7002 has finished!\n",
      "60 images in 7002 has finished!\n",
      "70 images in 7002 has finished!\n",
      "80 images in 7002 has finished!\n",
      "90 images in 7002 has finished!\n",
      "100 images in 7002 has finished!\n",
      "110 images in 7002 has finished!\n",
      "120 images in 7002 has finished!\n",
      "130 images in 7002 has finished!\n",
      "140 images in 7002 has finished!\n",
      "150 images in 7002 has finished!\n",
      "160 images in 7002 has finished!\n",
      "170 images in 7002 has finished!\n",
      "180 images in 7002 has finished!\n",
      "190 images in 7002 has finished!\n",
      "200 images in 7002 has finished!\n",
      "210 images in 7002 has finished!\n",
      "220 images in 7002 has finished!\n",
      "230 images in 7002 has finished!\n",
      "240 images in 7002 has finished!\n",
      "250 images in 7002 has finished!\n",
      "260 images in 7002 has finished!\n",
      "270 images in 7002 has finished!\n",
      "280 images in 7002 has finished!\n",
      "290 images in 7002 has finished!\n",
      "300 images in 7002 has finished!\n",
      "310 images in 7002 has finished!\n",
      "320 images in 7002 has finished!\n",
      "330 images in 7002 has finished!\n",
      "340 images in 7002 has finished!\n",
      "350 images in 7002 has finished!\n",
      "360 images in 7002 has finished!\n",
      "370 images in 7002 has finished!\n",
      "380 images in 7002 has finished!\n",
      "390 images in 7002 has finished!\n",
      "400 images in 7002 has finished!\n",
      "410 images in 7002 has finished!\n",
      "420 images in 7002 has finished!\n",
      "430 images in 7002 has finished!\n",
      "440 images in 7002 has finished!\n",
      "450 images in 7002 has finished!\n",
      "460 images in 7002 has finished!\n",
      "470 images in 7002 has finished!\n",
      "480 images in 7002 has finished!\n",
      "490 images in 7002 has finished!\n",
      "500 images in 7002 has finished!\n",
      "510 images in 7002 has finished!\n",
      "520 images in 7002 has finished!\n",
      "530 images in 7002 has finished!\n",
      "540 images in 7002 has finished!\n",
      "550 images in 7002 has finished!\n",
      "560 images in 7002 has finished!\n",
      "570 images in 7002 has finished!\n",
      "580 images in 7002 has finished!\n",
      "590 images in 7002 has finished!\n",
      "600 images in 7002 has finished!\n",
      "610 images in 7002 has finished!\n",
      "620 images in 7002 has finished!\n",
      "630 images in 7002 has finished!\n",
      "640 images in 7002 has finished!\n",
      "650 images in 7002 has finished!\n",
      "660 images in 7002 has finished!\n",
      "670 images in 7002 has finished!\n",
      "680 images in 7002 has finished!\n",
      "690 images in 7002 has finished!\n",
      "700 images in 7002 has finished!\n",
      "710 images in 7002 has finished!\n",
      "720 images in 7002 has finished!\n",
      "730 images in 7002 has finished!\n",
      "740 images in 7002 has finished!\n",
      "750 images in 7002 has finished!\n",
      "760 images in 7002 has finished!\n",
      "770 images in 7002 has finished!\n",
      "780 images in 7002 has finished!\n",
      "790 images in 7002 has finished!\n",
      "800 images in 7002 has finished!\n",
      "810 images in 7002 has finished!\n",
      "820 images in 7002 has finished!\n",
      "830 images in 7002 has finished!\n",
      "840 images in 7002 has finished!\n",
      "850 images in 7002 has finished!\n",
      "860 images in 7002 has finished!\n",
      "870 images in 7002 has finished!\n",
      "880 images in 7002 has finished!\n",
      "890 images in 7002 has finished!\n",
      "900 images in 7002 has finished!\n",
      "910 images in 7002 has finished!\n",
      "920 images in 7002 has finished!\n",
      "930 images in 7002 has finished!\n",
      "940 images in 7002 has finished!\n",
      "950 images in 7002 has finished!\n",
      "960 images in 7002 has finished!\n",
      "970 images in 7002 has finished!\n",
      "980 images in 7002 has finished!\n",
      "990 images in 7002 has finished!\n",
      "1000 images in 7002 has finished!\n",
      "1010 images in 7002 has finished!\n",
      "1020 images in 7002 has finished!\n",
      "1030 images in 7002 has finished!\n",
      "1040 images in 7002 has finished!\n",
      "1050 images in 7002 has finished!\n",
      "1060 images in 7002 has finished!\n",
      "1070 images in 7002 has finished!\n",
      "1080 images in 7002 has finished!\n",
      "1090 images in 7002 has finished!\n",
      "1100 images in 7002 has finished!\n",
      "1110 images in 7002 has finished!\n",
      "1120 images in 7002 has finished!\n",
      "1130 images in 7002 has finished!\n",
      "1140 images in 7002 has finished!\n",
      "1150 images in 7002 has finished!\n",
      "1160 images in 7002 has finished!\n",
      "1170 images in 7002 has finished!\n",
      "1180 images in 7002 has finished!\n",
      "1190 images in 7002 has finished!\n",
      "1200 images in 7002 has finished!\n",
      "1210 images in 7002 has finished!\n",
      "1220 images in 7002 has finished!\n",
      "1230 images in 7002 has finished!\n",
      "1240 images in 7002 has finished!\n",
      "1250 images in 7002 has finished!\n",
      "1260 images in 7002 has finished!\n",
      "1270 images in 7002 has finished!\n",
      "1280 images in 7002 has finished!\n",
      "1290 images in 7002 has finished!\n",
      "1300 images in 7002 has finished!\n",
      "1310 images in 7002 has finished!\n",
      "1320 images in 7002 has finished!\n",
      "1330 images in 7002 has finished!\n",
      "1340 images in 7002 has finished!\n",
      "1350 images in 7002 has finished!\n",
      "1360 images in 7002 has finished!\n",
      "1370 images in 7002 has finished!\n",
      "1380 images in 7002 has finished!\n",
      "1390 images in 7002 has finished!\n",
      "1400 images in 7002 has finished!\n",
      "1410 images in 7002 has finished!\n",
      "1420 images in 7002 has finished!\n",
      "1430 images in 7002 has finished!\n",
      "1440 images in 7002 has finished!\n",
      "1450 images in 7002 has finished!\n",
      "1460 images in 7002 has finished!\n",
      "1470 images in 7002 has finished!\n",
      "1480 images in 7002 has finished!\n",
      "1490 images in 7002 has finished!\n",
      "1500 images in 7002 has finished!\n",
      "1510 images in 7002 has finished!\n",
      "1520 images in 7002 has finished!\n",
      "1530 images in 7002 has finished!\n",
      "1540 images in 7002 has finished!\n",
      "1550 images in 7002 has finished!\n",
      "1560 images in 7002 has finished!\n",
      "1570 images in 7002 has finished!\n",
      "1580 images in 7002 has finished!\n",
      "1590 images in 7002 has finished!\n",
      "1600 images in 7002 has finished!\n",
      "1610 images in 7002 has finished!\n",
      "1620 images in 7002 has finished!\n",
      "1630 images in 7002 has finished!\n",
      "1640 images in 7002 has finished!\n",
      "1650 images in 7002 has finished!\n",
      "1660 images in 7002 has finished!\n",
      "1670 images in 7002 has finished!\n",
      "1680 images in 7002 has finished!\n",
      "1690 images in 7002 has finished!\n",
      "1700 images in 7002 has finished!\n",
      "1710 images in 7002 has finished!\n",
      "1720 images in 7002 has finished!\n",
      "1730 images in 7002 has finished!\n",
      "1740 images in 7002 has finished!\n",
      "1750 images in 7002 has finished!\n",
      "1760 images in 7002 has finished!\n",
      "1770 images in 7002 has finished!\n",
      "1780 images in 7002 has finished!\n",
      "1790 images in 7002 has finished!\n",
      "1800 images in 7002 has finished!\n",
      "1810 images in 7002 has finished!\n",
      "1820 images in 7002 has finished!\n",
      "1830 images in 7002 has finished!\n",
      "1840 images in 7002 has finished!\n",
      "1850 images in 7002 has finished!\n",
      "1860 images in 7002 has finished!\n",
      "1870 images in 7002 has finished!\n",
      "1880 images in 7002 has finished!\n",
      "1890 images in 7002 has finished!\n",
      "1900 images in 7002 has finished!\n",
      "1910 images in 7002 has finished!\n",
      "1920 images in 7002 has finished!\n",
      "1930 images in 7002 has finished!\n",
      "1940 images in 7002 has finished!\n",
      "1950 images in 7002 has finished!\n",
      "1960 images in 7002 has finished!\n",
      "1970 images in 7002 has finished!\n",
      "1980 images in 7002 has finished!\n",
      "1990 images in 7002 has finished!\n",
      "2000 images in 7002 has finished!\n",
      "2010 images in 7002 has finished!\n",
      "2020 images in 7002 has finished!\n",
      "2030 images in 7002 has finished!\n",
      "2040 images in 7002 has finished!\n",
      "2050 images in 7002 has finished!\n",
      "2060 images in 7002 has finished!\n",
      "2070 images in 7002 has finished!\n",
      "2080 images in 7002 has finished!\n",
      "2090 images in 7002 has finished!\n",
      "2100 images in 7002 has finished!\n",
      "2110 images in 7002 has finished!\n",
      "2120 images in 7002 has finished!\n",
      "2130 images in 7002 has finished!\n",
      "2140 images in 7002 has finished!\n",
      "2150 images in 7002 has finished!\n",
      "2160 images in 7002 has finished!\n",
      "2170 images in 7002 has finished!\n",
      "2180 images in 7002 has finished!\n",
      "2190 images in 7002 has finished!\n",
      "2200 images in 7002 has finished!\n",
      "2210 images in 7002 has finished!\n",
      "2220 images in 7002 has finished!\n",
      "2230 images in 7002 has finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2240 images in 7002 has finished!\n",
      "2250 images in 7002 has finished!\n",
      "2260 images in 7002 has finished!\n",
      "2270 images in 7002 has finished!\n",
      "2280 images in 7002 has finished!\n",
      "2290 images in 7002 has finished!\n",
      "2300 images in 7002 has finished!\n",
      "2310 images in 7002 has finished!\n",
      "2320 images in 7002 has finished!\n",
      "2330 images in 7002 has finished!\n",
      "2340 images in 7002 has finished!\n",
      "2350 images in 7002 has finished!\n",
      "2360 images in 7002 has finished!\n",
      "2370 images in 7002 has finished!\n",
      "2380 images in 7002 has finished!\n",
      "2390 images in 7002 has finished!\n",
      "2400 images in 7002 has finished!\n",
      "2410 images in 7002 has finished!\n",
      "2420 images in 7002 has finished!\n",
      "2430 images in 7002 has finished!\n",
      "2440 images in 7002 has finished!\n",
      "2450 images in 7002 has finished!\n",
      "2460 images in 7002 has finished!\n",
      "2470 images in 7002 has finished!\n",
      "2480 images in 7002 has finished!\n",
      "2490 images in 7002 has finished!\n",
      "2500 images in 7002 has finished!\n",
      "2510 images in 7002 has finished!\n",
      "2520 images in 7002 has finished!\n",
      "2530 images in 7002 has finished!\n",
      "2540 images in 7002 has finished!\n",
      "2550 images in 7002 has finished!\n",
      "2560 images in 7002 has finished!\n",
      "2570 images in 7002 has finished!\n",
      "2580 images in 7002 has finished!\n",
      "2590 images in 7002 has finished!\n",
      "2600 images in 7002 has finished!\n",
      "2610 images in 7002 has finished!\n",
      "2620 images in 7002 has finished!\n",
      "2630 images in 7002 has finished!\n",
      "2640 images in 7002 has finished!\n",
      "2650 images in 7002 has finished!\n",
      "2660 images in 7002 has finished!\n",
      "2670 images in 7002 has finished!\n",
      "2680 images in 7002 has finished!\n",
      "2690 images in 7002 has finished!\n",
      "2700 images in 7002 has finished!\n",
      "2710 images in 7002 has finished!\n",
      "2720 images in 7002 has finished!\n",
      "2730 images in 7002 has finished!\n",
      "2740 images in 7002 has finished!\n",
      "2750 images in 7002 has finished!\n",
      "2760 images in 7002 has finished!\n",
      "2770 images in 7002 has finished!\n",
      "2780 images in 7002 has finished!\n",
      "2790 images in 7002 has finished!\n",
      "2800 images in 7002 has finished!\n",
      "2810 images in 7002 has finished!\n",
      "2820 images in 7002 has finished!\n",
      "2830 images in 7002 has finished!\n",
      "2840 images in 7002 has finished!\n",
      "2850 images in 7002 has finished!\n",
      "2860 images in 7002 has finished!\n",
      "2870 images in 7002 has finished!\n",
      "2880 images in 7002 has finished!\n",
      "2890 images in 7002 has finished!\n",
      "2900 images in 7002 has finished!\n",
      "2910 images in 7002 has finished!\n",
      "2920 images in 7002 has finished!\n",
      "2930 images in 7002 has finished!\n",
      "2940 images in 7002 has finished!\n",
      "2950 images in 7002 has finished!\n",
      "2960 images in 7002 has finished!\n",
      "2970 images in 7002 has finished!\n",
      "2980 images in 7002 has finished!\n",
      "2990 images in 7002 has finished!\n",
      "3000 images in 7002 has finished!\n",
      "3010 images in 7002 has finished!\n",
      "3020 images in 7002 has finished!\n",
      "3030 images in 7002 has finished!\n",
      "3040 images in 7002 has finished!\n",
      "3050 images in 7002 has finished!\n",
      "3060 images in 7002 has finished!\n",
      "3070 images in 7002 has finished!\n",
      "3080 images in 7002 has finished!\n",
      "3090 images in 7002 has finished!\n",
      "3100 images in 7002 has finished!\n",
      "3110 images in 7002 has finished!\n",
      "3120 images in 7002 has finished!\n",
      "3130 images in 7002 has finished!\n",
      "3140 images in 7002 has finished!\n",
      "3150 images in 7002 has finished!\n",
      "3160 images in 7002 has finished!\n",
      "3170 images in 7002 has finished!\n",
      "3180 images in 7002 has finished!\n",
      "3190 images in 7002 has finished!\n",
      "3200 images in 7002 has finished!\n",
      "3210 images in 7002 has finished!\n",
      "3220 images in 7002 has finished!\n",
      "3230 images in 7002 has finished!\n",
      "3240 images in 7002 has finished!\n",
      "3250 images in 7002 has finished!\n",
      "3260 images in 7002 has finished!\n",
      "3270 images in 7002 has finished!\n",
      "3280 images in 7002 has finished!\n",
      "3290 images in 7002 has finished!\n",
      "3300 images in 7002 has finished!\n",
      "3310 images in 7002 has finished!\n",
      "3320 images in 7002 has finished!\n",
      "3330 images in 7002 has finished!\n",
      "3340 images in 7002 has finished!\n",
      "3350 images in 7002 has finished!\n",
      "3360 images in 7002 has finished!\n",
      "3370 images in 7002 has finished!\n",
      "3380 images in 7002 has finished!\n",
      "3390 images in 7002 has finished!\n",
      "3400 images in 7002 has finished!\n",
      "3410 images in 7002 has finished!\n",
      "3420 images in 7002 has finished!\n",
      "3430 images in 7002 has finished!\n",
      "3440 images in 7002 has finished!\n",
      "3450 images in 7002 has finished!\n",
      "3460 images in 7002 has finished!\n",
      "3470 images in 7002 has finished!\n",
      "3480 images in 7002 has finished!\n",
      "3490 images in 7002 has finished!\n",
      "3500 images in 7002 has finished!\n",
      "3510 images in 7002 has finished!\n",
      "3520 images in 7002 has finished!\n",
      "3530 images in 7002 has finished!\n",
      "3540 images in 7002 has finished!\n",
      "3550 images in 7002 has finished!\n",
      "3560 images in 7002 has finished!\n",
      "3570 images in 7002 has finished!\n",
      "3580 images in 7002 has finished!\n",
      "3590 images in 7002 has finished!\n",
      "3600 images in 7002 has finished!\n",
      "3610 images in 7002 has finished!\n",
      "3620 images in 7002 has finished!\n",
      "3630 images in 7002 has finished!\n",
      "3640 images in 7002 has finished!\n",
      "3650 images in 7002 has finished!\n",
      "3660 images in 7002 has finished!\n",
      "3670 images in 7002 has finished!\n",
      "3680 images in 7002 has finished!\n",
      "3690 images in 7002 has finished!\n",
      "3700 images in 7002 has finished!\n",
      "3710 images in 7002 has finished!\n",
      "3720 images in 7002 has finished!\n",
      "3730 images in 7002 has finished!\n",
      "3740 images in 7002 has finished!\n",
      "3750 images in 7002 has finished!\n",
      "3760 images in 7002 has finished!\n",
      "3770 images in 7002 has finished!\n",
      "3780 images in 7002 has finished!\n",
      "3790 images in 7002 has finished!\n",
      "3800 images in 7002 has finished!\n",
      "3810 images in 7002 has finished!\n",
      "3820 images in 7002 has finished!\n",
      "3830 images in 7002 has finished!\n",
      "3840 images in 7002 has finished!\n",
      "3850 images in 7002 has finished!\n",
      "3860 images in 7002 has finished!\n",
      "3870 images in 7002 has finished!\n",
      "3880 images in 7002 has finished!\n",
      "3890 images in 7002 has finished!\n",
      "3900 images in 7002 has finished!\n",
      "3910 images in 7002 has finished!\n",
      "3920 images in 7002 has finished!\n",
      "3930 images in 7002 has finished!\n",
      "3940 images in 7002 has finished!\n",
      "3950 images in 7002 has finished!\n",
      "3960 images in 7002 has finished!\n",
      "3970 images in 7002 has finished!\n",
      "3980 images in 7002 has finished!\n",
      "3990 images in 7002 has finished!\n",
      "4000 images in 7002 has finished!\n",
      "4010 images in 7002 has finished!\n",
      "4020 images in 7002 has finished!\n",
      "4030 images in 7002 has finished!\n",
      "4040 images in 7002 has finished!\n",
      "4050 images in 7002 has finished!\n",
      "4060 images in 7002 has finished!\n",
      "4070 images in 7002 has finished!\n",
      "4080 images in 7002 has finished!\n",
      "4090 images in 7002 has finished!\n",
      "4100 images in 7002 has finished!\n",
      "4110 images in 7002 has finished!\n",
      "4120 images in 7002 has finished!\n",
      "4130 images in 7002 has finished!\n",
      "4140 images in 7002 has finished!\n",
      "4150 images in 7002 has finished!\n",
      "4160 images in 7002 has finished!\n",
      "4170 images in 7002 has finished!\n",
      "4180 images in 7002 has finished!\n",
      "4190 images in 7002 has finished!\n",
      "4200 images in 7002 has finished!\n",
      "4210 images in 7002 has finished!\n",
      "4220 images in 7002 has finished!\n",
      "4230 images in 7002 has finished!\n",
      "4240 images in 7002 has finished!\n",
      "4250 images in 7002 has finished!\n",
      "4260 images in 7002 has finished!\n",
      "4270 images in 7002 has finished!\n",
      "4280 images in 7002 has finished!\n",
      "4290 images in 7002 has finished!\n",
      "4300 images in 7002 has finished!\n",
      "4310 images in 7002 has finished!\n",
      "4320 images in 7002 has finished!\n",
      "4330 images in 7002 has finished!\n",
      "4340 images in 7002 has finished!\n",
      "4350 images in 7002 has finished!\n",
      "4360 images in 7002 has finished!\n",
      "4370 images in 7002 has finished!\n",
      "4380 images in 7002 has finished!\n",
      "4390 images in 7002 has finished!\n",
      "4400 images in 7002 has finished!\n",
      "4410 images in 7002 has finished!\n",
      "4420 images in 7002 has finished!\n",
      "4430 images in 7002 has finished!\n",
      "4440 images in 7002 has finished!\n",
      "4450 images in 7002 has finished!\n",
      "4460 images in 7002 has finished!\n",
      "4470 images in 7002 has finished!\n",
      "4480 images in 7002 has finished!\n",
      "4490 images in 7002 has finished!\n",
      "4500 images in 7002 has finished!\n",
      "4510 images in 7002 has finished!\n",
      "4520 images in 7002 has finished!\n",
      "4530 images in 7002 has finished!\n",
      "4540 images in 7002 has finished!\n",
      "4550 images in 7002 has finished!\n",
      "4560 images in 7002 has finished!\n",
      "4570 images in 7002 has finished!\n",
      "4580 images in 7002 has finished!\n",
      "4590 images in 7002 has finished!\n",
      "4600 images in 7002 has finished!\n",
      "4610 images in 7002 has finished!\n",
      "4620 images in 7002 has finished!\n",
      "4630 images in 7002 has finished!\n",
      "4640 images in 7002 has finished!\n",
      "4650 images in 7002 has finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4660 images in 7002 has finished!\n",
      "4670 images in 7002 has finished!\n",
      "4680 images in 7002 has finished!\n",
      "4690 images in 7002 has finished!\n",
      "4700 images in 7002 has finished!\n",
      "4710 images in 7002 has finished!\n",
      "4720 images in 7002 has finished!\n",
      "4730 images in 7002 has finished!\n",
      "4740 images in 7002 has finished!\n",
      "4750 images in 7002 has finished!\n",
      "4760 images in 7002 has finished!\n",
      "4770 images in 7002 has finished!\n",
      "4780 images in 7002 has finished!\n",
      "4790 images in 7002 has finished!\n",
      "4800 images in 7002 has finished!\n",
      "4810 images in 7002 has finished!\n",
      "4820 images in 7002 has finished!\n",
      "4830 images in 7002 has finished!\n",
      "4840 images in 7002 has finished!\n",
      "4850 images in 7002 has finished!\n",
      "4860 images in 7002 has finished!\n",
      "4870 images in 7002 has finished!\n",
      "4880 images in 7002 has finished!\n",
      "4890 images in 7002 has finished!\n",
      "4900 images in 7002 has finished!\n",
      "4910 images in 7002 has finished!\n",
      "4920 images in 7002 has finished!\n",
      "4930 images in 7002 has finished!\n",
      "4940 images in 7002 has finished!\n",
      "4950 images in 7002 has finished!\n",
      "4960 images in 7002 has finished!\n",
      "4970 images in 7002 has finished!\n",
      "4980 images in 7002 has finished!\n",
      "4990 images in 7002 has finished!\n",
      "5000 images in 7002 has finished!\n",
      "5010 images in 7002 has finished!\n",
      "5020 images in 7002 has finished!\n",
      "5030 images in 7002 has finished!\n",
      "5040 images in 7002 has finished!\n",
      "5050 images in 7002 has finished!\n",
      "5060 images in 7002 has finished!\n",
      "5070 images in 7002 has finished!\n",
      "5080 images in 7002 has finished!\n",
      "5090 images in 7002 has finished!\n",
      "5100 images in 7002 has finished!\n",
      "5110 images in 7002 has finished!\n",
      "5120 images in 7002 has finished!\n",
      "5130 images in 7002 has finished!\n",
      "5140 images in 7002 has finished!\n",
      "5150 images in 7002 has finished!\n",
      "5160 images in 7002 has finished!\n",
      "5170 images in 7002 has finished!\n",
      "5180 images in 7002 has finished!\n",
      "5190 images in 7002 has finished!\n",
      "5200 images in 7002 has finished!\n",
      "5210 images in 7002 has finished!\n",
      "5220 images in 7002 has finished!\n",
      "5230 images in 7002 has finished!\n",
      "5240 images in 7002 has finished!\n",
      "5250 images in 7002 has finished!\n",
      "5260 images in 7002 has finished!\n",
      "5270 images in 7002 has finished!\n",
      "5280 images in 7002 has finished!\n",
      "5290 images in 7002 has finished!\n",
      "5300 images in 7002 has finished!\n",
      "5310 images in 7002 has finished!\n",
      "5320 images in 7002 has finished!\n",
      "5330 images in 7002 has finished!\n",
      "5340 images in 7002 has finished!\n",
      "5350 images in 7002 has finished!\n",
      "5360 images in 7002 has finished!\n",
      "5370 images in 7002 has finished!\n",
      "5380 images in 7002 has finished!\n",
      "5390 images in 7002 has finished!\n",
      "5400 images in 7002 has finished!\n",
      "5410 images in 7002 has finished!\n",
      "5420 images in 7002 has finished!\n",
      "5430 images in 7002 has finished!\n",
      "5440 images in 7002 has finished!\n",
      "5450 images in 7002 has finished!\n",
      "5460 images in 7002 has finished!\n",
      "5470 images in 7002 has finished!\n",
      "5480 images in 7002 has finished!\n",
      "5490 images in 7002 has finished!\n",
      "5500 images in 7002 has finished!\n",
      "5510 images in 7002 has finished!\n",
      "5520 images in 7002 has finished!\n",
      "5530 images in 7002 has finished!\n",
      "5540 images in 7002 has finished!\n",
      "5550 images in 7002 has finished!\n",
      "5560 images in 7002 has finished!\n",
      "5570 images in 7002 has finished!\n",
      "5580 images in 7002 has finished!\n",
      "5590 images in 7002 has finished!\n",
      "5600 images in 7002 has finished!\n",
      "5610 images in 7002 has finished!\n",
      "5620 images in 7002 has finished!\n",
      "5630 images in 7002 has finished!\n",
      "5640 images in 7002 has finished!\n",
      "5650 images in 7002 has finished!\n",
      "5660 images in 7002 has finished!\n",
      "5670 images in 7002 has finished!\n",
      "5680 images in 7002 has finished!\n",
      "5690 images in 7002 has finished!\n",
      "5700 images in 7002 has finished!\n",
      "5710 images in 7002 has finished!\n",
      "5720 images in 7002 has finished!\n",
      "5730 images in 7002 has finished!\n",
      "5740 images in 7002 has finished!\n",
      "5750 images in 7002 has finished!\n",
      "5760 images in 7002 has finished!\n",
      "5770 images in 7002 has finished!\n",
      "5780 images in 7002 has finished!\n",
      "5790 images in 7002 has finished!\n",
      "5800 images in 7002 has finished!\n",
      "5810 images in 7002 has finished!\n",
      "5820 images in 7002 has finished!\n",
      "5830 images in 7002 has finished!\n",
      "5840 images in 7002 has finished!\n",
      "5850 images in 7002 has finished!\n",
      "5860 images in 7002 has finished!\n",
      "5870 images in 7002 has finished!\n",
      "5880 images in 7002 has finished!\n",
      "5890 images in 7002 has finished!\n",
      "5900 images in 7002 has finished!\n",
      "5910 images in 7002 has finished!\n",
      "5920 images in 7002 has finished!\n",
      "5930 images in 7002 has finished!\n",
      "5940 images in 7002 has finished!\n",
      "5950 images in 7002 has finished!\n",
      "5960 images in 7002 has finished!\n",
      "5970 images in 7002 has finished!\n",
      "5980 images in 7002 has finished!\n",
      "5990 images in 7002 has finished!\n",
      "6000 images in 7002 has finished!\n",
      "6010 images in 7002 has finished!\n",
      "6020 images in 7002 has finished!\n",
      "6030 images in 7002 has finished!\n",
      "6040 images in 7002 has finished!\n",
      "6050 images in 7002 has finished!\n",
      "6060 images in 7002 has finished!\n",
      "6070 images in 7002 has finished!\n",
      "6080 images in 7002 has finished!\n",
      "6090 images in 7002 has finished!\n",
      "6100 images in 7002 has finished!\n",
      "6110 images in 7002 has finished!\n",
      "6120 images in 7002 has finished!\n",
      "6130 images in 7002 has finished!\n",
      "6140 images in 7002 has finished!\n",
      "6150 images in 7002 has finished!\n",
      "6160 images in 7002 has finished!\n",
      "6170 images in 7002 has finished!\n",
      "6180 images in 7002 has finished!\n",
      "6190 images in 7002 has finished!\n",
      "6200 images in 7002 has finished!\n",
      "6210 images in 7002 has finished!\n",
      "6220 images in 7002 has finished!\n",
      "6230 images in 7002 has finished!\n",
      "6240 images in 7002 has finished!\n",
      "6250 images in 7002 has finished!\n",
      "6260 images in 7002 has finished!\n",
      "6270 images in 7002 has finished!\n",
      "6280 images in 7002 has finished!\n",
      "6290 images in 7002 has finished!\n",
      "6300 images in 7002 has finished!\n",
      "6310 images in 7002 has finished!\n",
      "6320 images in 7002 has finished!\n",
      "6330 images in 7002 has finished!\n",
      "6340 images in 7002 has finished!\n",
      "6350 images in 7002 has finished!\n",
      "6360 images in 7002 has finished!\n",
      "6370 images in 7002 has finished!\n",
      "6380 images in 7002 has finished!\n",
      "6390 images in 7002 has finished!\n",
      "6400 images in 7002 has finished!\n",
      "6410 images in 7002 has finished!\n",
      "6420 images in 7002 has finished!\n",
      "6430 images in 7002 has finished!\n",
      "6440 images in 7002 has finished!\n",
      "6450 images in 7002 has finished!\n",
      "6460 images in 7002 has finished!\n",
      "6470 images in 7002 has finished!\n",
      "6480 images in 7002 has finished!\n",
      "6490 images in 7002 has finished!\n",
      "6500 images in 7002 has finished!\n",
      "6510 images in 7002 has finished!\n",
      "6520 images in 7002 has finished!\n",
      "6530 images in 7002 has finished!\n",
      "6540 images in 7002 has finished!\n",
      "6550 images in 7002 has finished!\n",
      "6560 images in 7002 has finished!\n",
      "6570 images in 7002 has finished!\n",
      "6580 images in 7002 has finished!\n",
      "6590 images in 7002 has finished!\n",
      "6600 images in 7002 has finished!\n",
      "6610 images in 7002 has finished!\n",
      "6620 images in 7002 has finished!\n",
      "6630 images in 7002 has finished!\n",
      "6640 images in 7002 has finished!\n",
      "6650 images in 7002 has finished!\n",
      "6660 images in 7002 has finished!\n",
      "6670 images in 7002 has finished!\n",
      "6680 images in 7002 has finished!\n",
      "6690 images in 7002 has finished!\n",
      "6700 images in 7002 has finished!\n",
      "6710 images in 7002 has finished!\n",
      "6720 images in 7002 has finished!\n",
      "6730 images in 7002 has finished!\n",
      "6740 images in 7002 has finished!\n",
      "6750 images in 7002 has finished!\n",
      "6760 images in 7002 has finished!\n",
      "6770 images in 7002 has finished!\n",
      "6780 images in 7002 has finished!\n",
      "6790 images in 7002 has finished!\n",
      "6800 images in 7002 has finished!\n",
      "6810 images in 7002 has finished!\n",
      "6820 images in 7002 has finished!\n",
      "6830 images in 7002 has finished!\n",
      "6840 images in 7002 has finished!\n",
      "6850 images in 7002 has finished!\n",
      "6860 images in 7002 has finished!\n",
      "6870 images in 7002 has finished!\n",
      "6880 images in 7002 has finished!\n",
      "6890 images in 7002 has finished!\n",
      "6900 images in 7002 has finished!\n",
      "6910 images in 7002 has finished!\n",
      "6920 images in 7002 has finished!\n",
      "6930 images in 7002 has finished!\n",
      "6940 images in 7002 has finished!\n",
      "6950 images in 7002 has finished!\n",
      "6960 images in 7002 has finished!\n",
      "6970 images in 7002 has finished!\n",
      "6980 images in 7002 has finished!\n",
      "6990 images in 7002 has finished!\n",
      "7000 images in 7002 has finished!\n",
      "Complete!!\n",
      "cd to current directory, the folder 'resized_image' should contains 7002 images with 480x640 size.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimages, sparse_labels = tf.train.shuffle_batch(\\n        [image, label], \\n        batch_size = 5, \\n        num_threads=2, \\n        capacity = 10, \\n        min_after_dequeue= 5)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from dir_traversal_tfrecord import tfrecord_auto_traversal\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer(\"image_number\", 7002, \"Number of images in your tfrecord, default is 300.\")\n",
    "flags.DEFINE_integer(\"class_number\", 2, \"Number of class in your dataset/label.txt, default is 3.\")\n",
    "flags.DEFINE_integer(\"image_height\", 480, \"Height of the output image after crop and resize. Default is 299.\")\n",
    "flags.DEFINE_integer(\"image_width\", 640, \"Width of the output image after crop and resize. Default is 299.\")\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
    "  if not isinstance(value, list):\n",
    "    value = [value]\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "class image_object:\n",
    "    def __init__(self):\n",
    "        self.image = tf.Variable([], dtype = tf.string)\n",
    "        self.height = tf.Variable([], dtype = tf.int64)\n",
    "        self.width = tf.Variable([], dtype = tf.int64)\n",
    "        self.filename = tf.Variable([], dtype = tf.string)\n",
    "        self.label = tf.Variable([], dtype = tf.int32)\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example, features = {\n",
    "        \"image/encoded\": tf.FixedLenFeature([], tf.string),\n",
    "        \"image/height\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"image/width\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"image/filename\": tf.FixedLenFeature([], tf.string),\n",
    "        \"image/class/label\": tf.FixedLenFeature([], tf.int64),})\n",
    "\n",
    "    image_encoded = features[\"image/encoded\"]\n",
    "    image_raw = tf.image.decode_jpeg(image_encoded, channels=3)\n",
    "\n",
    "    current_image_object = image_object()\n",
    "\n",
    "    current_image_object.image = tf.image.resize_image_with_crop_or_pad(image_raw, FLAGS.image_height, FLAGS.image_width) # cropped image with size 299x299\n",
    "#    current_image_object.image = tf.cast(image_crop, tf.float32) * (1./255) - 0.5\n",
    "    current_image_object.height = features[\"image/height\"] # height of the raw image\n",
    "    current_image_object.width = features[\"image/width\"] # width of the raw image\n",
    "    current_image_object.filename = features[\"image/filename\"] # filename of the raw image\n",
    "    current_image_object.label = tf.cast(features[\"image/class/label\"], tf.int32) # label of the raw image\n",
    "    \n",
    "    return current_image_object\n",
    "\n",
    "\n",
    "def generate_mini_batch(image, label, batch_size = 50):\n",
    "    images, labels = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size = batch_size,\n",
    "        capacity = min_queue_examples + 3 * batch_size,\n",
    "        min_after_dequeue = min_queue_examples\n",
    "    )\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "        tfrecord_auto_traversal(),\n",
    "        shuffle = True)\n",
    "\n",
    "\n",
    "current_image_object = read_and_decode(filename_queue)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    print(\"Write cropped and resized image to the folder './resized_image'\") \n",
    "    for i in range(FLAGS.image_number): # number of examples in your tfrecord\n",
    "        pre_image, pre_label = sess.run([current_image_object.image, current_image_object.label])\n",
    "        img = Image.fromarray(pre_image, \"RGB\")\n",
    "        if not os.path.isdir(\"./resized_image/\"):\n",
    "            os.mkdir(\"./resized_image\")\n",
    "        img.save(os.path.join(\"./resized_image/class_\"+str(pre_label)+\"_Index_\"+str(i)+\".jpeg\"))\n",
    "        if i % 10 == 0:\n",
    "            print (\"%d images in %d has finished!\" % (i, FLAGS.image_number))\n",
    "    print(\"Complete!!\")\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "\n",
    "print(\"cd to current directory, the folder 'resized_image' should contains %d images with %dx%d size.\" % (FLAGS.image_number,FLAGS.image_height, FLAGS.image_width))\n",
    "\n",
    "\"\"\"\n",
    "images, sparse_labels = tf.train.shuffle_batch(\n",
    "        [image, label], \n",
    "        batch_size = 5, \n",
    "        num_threads=2, \n",
    "        capacity = 10, \n",
    "        min_after_dequeue= 5)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: caokai\n",
    "\"\"\"\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import ReadMyOwnData\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "#initial weights\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "#initial bias\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#convolution layer\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "#max_pool layer\n",
    "def max_pool_4x4(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,4,4,1], strides=[1,4,4,1], padding='SAME')\n",
    "\n",
    "x = tf.placeholder(tf.float32, [batch_size,128,128,3])\n",
    "y_ = tf.placeholder(tf.float32, [batch_size,1])\n",
    "\n",
    "#first convolution and max_pool layer\n",
    "W_conv1 = weight_variable([5,5,3,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_4x4(h_conv1)\n",
    "\n",
    "#second convolution and max_pool layer\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_4x4(h_conv2)\n",
    "\n",
    "#MLP\n",
    "reshape = tf.reshape(h_pool2,[batch_size, -1])\n",
    "dim = reshape.get_shape()[1].value\n",
    "W_fc1 = weight_variable([dim, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(reshape, W_fc1) + b_fc1)\n",
    "\n",
    "#dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024,2])\n",
    "b_fc2 = bias_variable([2])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "#\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-678f94bea0ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReadMyOwnData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_and_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train-00001-of-00002.tfrecord\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcoord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "image, label = ReadMyOwnData.read_and_decode(\"train-00001-of-00002.tfrecord\")\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "coord=tf.train.Coordinator()\n",
    "threads= tf.train.start_queue_runners(coord=coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
