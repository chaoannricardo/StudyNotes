{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\ricardo\\\\Github\\\\Kaggle\\\\1910_TMU_EnglishReviewClassification\\\\Data\\\\training_dataset_v1\\\\training_dataset\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 ['neg', 'pos']\n",
      "./pos\\11485_10.txt 1 b'Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and act'\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "data_path = \"./\"\n",
    "mrdataset = load_files(data_path, shuffle=True)\n",
    "\n",
    "print(len(mrdataset.data), mrdataset.target_names)\n",
    "print(mrdataset.filenames[0], \n",
    "     mrdataset.target[0],\n",
    "     mrdataset.data[0][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8647600000000001\n"
     ]
    }
   ],
   "source": [
    "# NB using SKLearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "performance = cross_val_score(model, tfidf_vectorizer.fit_transform(mrdataset.data),\n",
    "                             mrdataset.target, cv=10, scoring='accuracy')\n",
    "print(performance.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7749600000000001\n"
     ]
    }
   ],
   "source": [
    "# KNN with sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "performance = cross_val_score(model, tfidf_vectorizer.fit_transform(mrdataset.data),\n",
    "                             mrdataset.target, cv=10, scoring='accuracy')\n",
    "\n",
    "print(performance.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricardo\\Anaconda3\\envs\\Monpa\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "performance = cross_val_score(model, tfidf_vectorizer.fit_transform(mrdataset.data),\n",
    "                             mrdataset.target, cv=10, scoring='accuracy')\n",
    "print(performance.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC(kernel= 'linear')\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "performance = cross_val_score(model, tfidf_vectorizer.fit_transform(mrdataset.data),\n",
    "                             mrdataset.target, cv=10, scoring='accuracy')\n",
    "print(performance.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logestic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model =  LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "performance = cross_val_score(model, tfidf_vectorizer.fit_transform(mrdataset.data),\n",
    "                             mrdataset.target, cv=10, scoring='accuracy')\n",
    "print(performance.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model =  DecisionTreeClassifier(random_state=0)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "performance = cross_val_score(model, tfidf_vectorizer.fit_transform(mrdataset.data),\n",
    "                             mrdataset.target, cv=10, scoring='accuracy')\n",
    "print(performance.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model =  RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "performance = cross_val_score(model, tfidf_vectorizer.fit_transform(mrdataset.data),\n",
    "                             mrdataset.target, cv=10, scoring='accuracy')\n",
    "print(performance.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg',\n",
       " 'pos',\n",
       " 'train_dataframe.csv',\n",
       " 'train_dataframe.hdf5',\n",
       " 'train_dataframe.json']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"C:/Users/ricardo/Documents/GitHub/College/Courses/10801_MachineLearningAndDeepLearning/Assignments/Assignment_2/Data/training_dataset_v1/training_dataset\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 ['neg', 'pos']\n",
      "./pos\\11485_10.txt 1 b'Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and act'\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "import sklearn\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "data_path = \"./\"\n",
    "mrdataset = load_files(data_path, shuffle=True)\n",
    "\n",
    "print(len(mrdataset.data), mrdataset.target_names)\n",
    "print(mrdataset.filenames[0], \n",
    "     mrdataset.target[0],\n",
    "     mrdataset.data[0][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB using SKLearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "performance = cross_val_score(model, tfidf_vectorizer.fit_transform(mrdataset.data),\n",
    "                             mrdataset.target, cv=10, scoring='accuracy')\n",
    "print(performance.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv(\"../../test_dataset.csv\", header=None)\n",
    "\n",
    "test_list = test_data.iloc[:, 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-f9ea85ade4eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m predict_list = model.fit(tfidf_vectorizer.fit_transform(mrdataset.data), \n\u001b[1;32m---> 10\u001b[1;33m           mrdataset.target).predict(tfidf_vectorizer.fit_transform(test_data.iloc[:, 1].values.astype('U')))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Monpa\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Monpa\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[0m\u001b[0;32m    738\u001b[0m                 self.class_log_prior_)\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Monpa\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \"\"\"\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"toarray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Monpa\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "# NB using SKLearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = MultinomialNB()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "predict_list = model.fit(tfidf_vectorizer.fit_transform(mrdataset.data), \n",
    "          mrdataset.target).predict(tfidf_vectorizer.fit_transform(test_data.iloc[:, 1].values.astype('U')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 74609)\t0.10400144834656315\n",
      "  (0, 16697)\t0.06616363599010389\n",
      "  (0, 38088)\t0.08903178953833962\n",
      "  (0, 74324)\t0.06236169426500653\n",
      "  (0, 67125)\t0.0825231694319005\n",
      "  (0, 66526)\t0.09800051786804972\n",
      "  (0, 22718)\t0.040532410874261376\n",
      "  (0, 53749)\t0.05804792740830466\n",
      "  (0, 72965)\t0.05554019945351925\n",
      "  (0, 68769)\t0.1522591505433213\n",
      "  (0, 8714)\t0.096010752733501\n",
      "  (0, 74334)\t0.1249430990876082\n",
      "  (0, 42153)\t0.0755363101585969\n",
      "  (0, 73714)\t0.041207908987117396\n",
      "  (0, 19326)\t0.04510409865043369\n",
      "  (0, 72703)\t0.11193392879093665\n",
      "  (0, 66474)\t0.03561467680545796\n",
      "  (0, 18292)\t0.05160270108222595\n",
      "  (0, 13616)\t0.1225593240789404\n",
      "  (0, 44618)\t0.27171123269517194\n",
      "  (0, 64223)\t0.2129100905169705\n",
      "  (0, 71205)\t0.23395127327589701\n",
      "  (0, 60766)\t0.16339894731729804\n",
      "  (0, 66367)\t0.08829562718306676\n",
      "  (0, 12694)\t0.1458749804644132\n",
      "  :\t:\n",
      "  (24999, 61145)\t0.07037440478704826\n",
      "  (24999, 60890)\t0.07913457433071029\n",
      "  (24999, 71547)\t0.061168445081782354\n",
      "  (24999, 6566)\t0.10178585925341346\n",
      "  (24999, 49771)\t0.08493575597379098\n",
      "  (24999, 30793)\t0.07534564597443828\n",
      "  (24999, 71923)\t0.09581007769929444\n",
      "  (24999, 3768)\t0.07913457433071029\n",
      "  (24999, 35655)\t0.0830304753383565\n",
      "  (24999, 52957)\t0.08723782562408394\n",
      "  (24999, 57602)\t0.07372027301625639\n",
      "  (24999, 57958)\t0.0876726603843879\n",
      "  (24999, 56872)\t0.09492265498800216\n",
      "  (24999, 55409)\t0.08681940369462851\n",
      "  (24999, 65491)\t0.08602714779266907\n",
      "  (24999, 12814)\t0.07913457433071029\n",
      "  (24999, 21298)\t0.10030541470162742\n",
      "  (24999, 16972)\t0.09410102988949524\n",
      "  (24999, 39120)\t0.07423603415932584\n",
      "  (24999, 60827)\t0.166060950676713\n",
      "  (24999, 15682)\t0.10799024406554564\n",
      "  (24999, 62454)\t0.0926205853377092\n",
      "  (24999, 46435)\t0.09677476110801105\n",
      "  (24999, 49028)\t0.1111797364271309\n",
      "  (24999, 45930)\t0.11567507342946386\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.fit_transform(mrdataset.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7150)\t0.03990619059748804\n",
      "  (0, 11845)\t0.16732473436697684\n",
      "  (0, 4933)\t0.12296383915470796\n",
      "  (0, 1275)\t0.0603997013426767\n",
      "  (0, 5994)\t0.08367854386017783\n",
      "  (0, 12296)\t0.06364005153033803\n",
      "  (0, 12248)\t0.04128332382076268\n",
      "  (0, 6674)\t0.07722432410417583\n",
      "  (0, 2006)\t0.08050084539443265\n",
      "  (0, 10458)\t0.14005170339213743\n",
      "  (0, 12438)\t0.06876685120079724\n",
      "  (0, 7893)\t0.14694496550851777\n",
      "  (0, 8344)\t0.20857188086083484\n",
      "  (0, 12235)\t0.05570608813837777\n",
      "  (0, 1005)\t0.04097398113909583\n",
      "  (0, 4088)\t0.04009381705028927\n",
      "  (0, 2801)\t0.050185843043907365\n",
      "  (0, 1208)\t0.036958854018015234\n",
      "  (0, 1809)\t0.09384974512159266\n",
      "  (0, 12218)\t0.15239623464529206\n",
      "  (0, 5489)\t0.13374508112709185\n",
      "  (0, 538)\t0.032186211079493286\n",
      "  (0, 7936)\t0.038802433832921056\n",
      "  (0, 11877)\t0.11501843475868041\n",
      "  (0, 930)\t0.17064073669465488\n",
      "  :\t:\n",
      "  (5985, 12637)\t0.03637006278629925\n",
      "  (5985, 853)\t0.034256529609477664\n",
      "  (5985, 3143)\t0.034256529609477664\n",
      "  (5985, 8444)\t0.034256529609477664\n",
      "  (5985, 5510)\t0.033726877628011\n",
      "  (5985, 10700)\t0.034256529609477664\n",
      "  (5985, 8801)\t0.03737350461004268\n",
      "  (5985, 6964)\t0.03637006278629925\n",
      "  (5985, 13242)\t0.03737350461004268\n",
      "  (5985, 6333)\t0.03637006278629925\n",
      "  (5985, 12903)\t0.03555019111902684\n",
      "  (5985, 6613)\t0.034856999501406014\n",
      "  (5985, 2681)\t0.03737350461004268\n",
      "  (5985, 12492)\t0.03737350461004268\n",
      "  (5985, 10202)\t0.03637006278629925\n",
      "  (5985, 699)\t0.03637006278629925\n",
      "  (5985, 426)\t0.03737350461004268\n",
      "  (5985, 3523)\t0.03637006278629925\n",
      "  (5985, 5685)\t0.038667166119591846\n",
      "  (5985, 10036)\t0.040490479610607685\n",
      "  (5985, 8483)\t0.040490479610607685\n",
      "  (5985, 12568)\t0.040490479610607685\n",
      "  (5985, 12928)\t0.040490479610607685\n",
      "  (5985, 2735)\t0.040490479610607685\n",
      "  (5985, 12169)\t0.040490479610607685\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.fit_transform(test_data.iloc[:, 1].values.astype('U')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_test_list = []\n",
    "\n",
    "for i, j in enumerate(test_list):\n",
    "    if j != np.nan:\n",
    "        new_test_list.append(j)\n",
    "        \n",
    "print(len(new_test_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Monpa",
   "language": "python",
   "name": "monpa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
