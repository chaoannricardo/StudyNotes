{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "0            4.927         3.696          1.514         0.247\n",
      "1            5.524         2.828          4.129         1.184\n",
      "2            5.114         3.521          1.287         0.262\n",
      "3            5.947         2.607          5.228         2.038\n",
      "4            4.835         3.440          1.345         0.190\n",
      "5            4.893         3.335          1.447         0.225\n",
      "6            6.347         2.805          5.602         2.226\n",
      "7            6.469         3.106          5.510         1.942\n",
      "8            5.500         2.300          4.000         1.300\n",
      "9            5.919         2.777          4.266         1.312\n",
      "10           7.700         3.800          6.700         2.200\n",
      "11           5.061         3.315          1.501         0.215\n",
      "12           6.381         2.572          3.711         1.501\n",
      "13           5.867         3.024          4.019         1.525\n",
      "14           5.723         2.521          4.063         1.451\n",
      "15           4.960         3.422          1.486         0.220\n",
      "16           6.200         2.900          4.300         1.300\n",
      "17           6.400         3.100          5.500         1.800\n",
      "18           5.971         2.762          4.304         1.333\n",
      "19           4.900         3.100          1.500         0.100\n",
      "20           5.101         3.213          1.398         0.278\n",
      "21           6.616         2.937          5.497         1.933\n",
      "22           6.158         3.116          5.572         2.021\n",
      "23           6.516         3.378          5.573         1.699\n",
      "24           5.079         3.388          1.485         0.254\n",
      "25           6.638         2.907          5.403         1.959\n",
      "26           6.691         2.222          5.163         1.379\n",
      "27           6.300         2.500          4.900         1.500\n",
      "28           6.643         2.876          5.600         1.969\n",
      "29           7.029         3.051          5.708         1.964\n",
      "..             ...           ...            ...           ...\n",
      "870          4.355         3.021          1.240         0.195\n",
      "871          6.022         3.156          5.428         2.205\n",
      "872          5.897         2.447          4.256         1.309\n",
      "873          5.400         3.700          1.500         0.200\n",
      "874          6.095         3.010          5.679         1.908\n",
      "875          5.000         3.406          1.467         0.238\n",
      "876          6.032         2.705          4.322         1.349\n",
      "877          4.993         3.520          1.647         0.223\n",
      "878          4.984         3.407          1.453         0.244\n",
      "879          4.700         3.200          1.300         0.200\n",
      "880          5.885         3.021          3.686         1.048\n",
      "881          4.988         3.929          1.214         0.248\n",
      "882          4.757         3.474          1.374         0.254\n",
      "883          5.724         2.884          4.568         1.303\n",
      "884          5.790         2.718          3.994         1.379\n",
      "885          5.535         3.407          1.377         0.344\n",
      "886          6.982         2.826          5.622         1.933\n",
      "887          5.306         3.831          1.501         0.236\n",
      "888          6.912         3.008          5.666         2.001\n",
      "889          4.987         3.400          1.461         0.249\n",
      "890          6.635         2.972          5.602         2.047\n",
      "891          6.621         2.855          5.633         1.842\n",
      "892          7.168         2.734          6.065         2.378\n",
      "893          5.027         3.189          1.559         0.245\n",
      "894          4.894         3.410          1.407         0.255\n",
      "895          4.935         3.148          1.544         0.226\n",
      "896          5.637         2.700          4.465         1.308\n",
      "897          6.394         2.822          4.290         1.500\n",
      "898          6.034         2.843          4.323         1.384\n",
      "899          4.963         3.697          1.294         0.283\n",
      "\n",
      "[900 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv(\"./new_iris_training.csv\")\n",
    "X = training_data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "y = training_data.loc[:,'Species']\n",
    "#X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.3, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "from pprint import pprint\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  7.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_s...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 10, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(X, y)\n",
    "#y_pred = clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 30,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {'n_estimators': [2000],\n",
    " 'min_samples_split': [10],\n",
    " 'min_samples_leaf': [1],\n",
    " 'max_features': ['sqrt'],\n",
    " 'max_depth': [10],\n",
    " 'bootstrap': [False]}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix = pd.crosstab(y_validation, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "#sn.heatmap(confusion_matrix, annot=True)\n",
    "#print('Accuracy Score',  metrics.accuracy_score(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
      "0          5.933         2.770          4.244         1.310      NaN\n",
      "1          6.637         2.736          5.725         1.981      NaN\n",
      "2          5.434         2.747          4.239         1.373      NaN\n",
      "3          5.099         3.358          1.515         0.222      NaN\n",
      "4          5.011         3.431          1.461         0.256      NaN\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.read_csv('./new_iris_test.csv')\n",
    "print(data_test.head(5))\n",
    "X_test = data_test[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Id     Species\n",
      "0    1  versicolor\n",
      "1    2   virginica\n",
      "2    3  versicolor\n",
      "3    4      setosa\n",
      "4    5      setosa\n",
      "5    6   virginica\n",
      "6    7      setosa\n",
      "7    8   virginica\n",
      "8    9      setosa\n",
      "9   10  versicolor\n",
      "10  11      setosa\n",
      "11  12   virginica\n",
      "12  13  versicolor\n",
      "13  14      setosa\n",
      "14  15      setosa\n",
      "15  16  versicolor\n",
      "16  17   virginica\n",
      "17  18      setosa\n",
      "18  19   virginica\n",
      "19  20  versicolor\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(\"./iris_submission.csv\")\n",
    "submission.loc[:,'Species'] = test_pred\n",
    "print(submission.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./191018_3_finished_iris_submission.csv\", index=None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
