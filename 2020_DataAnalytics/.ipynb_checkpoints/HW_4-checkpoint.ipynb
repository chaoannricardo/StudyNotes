{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "<img src='./picture_source/HW_4_1.PNG' width='500px' align='middle'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "<img src='./picture_source/HW_4_2.PNG' width='500px' align='middle'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages needed \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "ORL_data = pd.read_csv('./data/ORL_data.csv')\n",
    "# divide into X and y\n",
    "X = ORL_data.iloc[:, :-1]\n",
    "y = ORL_data.iloc[:, -1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.358327951982005e-30, 6.190667701592344e-10, 2.4742769338365725e-09, 5.562652867408319e-09, 9.881227038391948e-09, 1.5427041958742524e-08, 2.2197150138341168e-08, 3.018861403887105e-08, 3.939850602783197e-08, 4.982390833288439e-08, 6.146191299670128e-08, 7.430962183149643e-08, 8.836414637449413e-08, 1.0362260784328066e-07, 1.2008213709152045e-07, 1.377398745648675e-07, 1.565929702572056e-07, 1.7663858366716706e-07, 1.978738837548968e-07, 2.2029604889900074e-07, 2.439022668537179e-07, 2.6868973470664835e-07, 2.946556588362488e-07, 3.2179725486996396e-07, 3.50111747642483e-07, 3.7959637115413697e-07, 4.10248368529745e-07, 4.420649919773396e-07, 4.750435027476531e-07, 5.091811710936651e-07, 5.44475276229805e-07, 5.809231062920818e-07, 6.185219582987189e-07, 6.572691381094903e-07, 6.971619603873312e-07, 7.381977485585714e-07, 7.803738347743159e-07, 8.236875598716551e-07, 8.681362733347679e-07, 9.137173332572158e-07, 9.60428106303887e-07, 1.0082659676722173e-06, 1.057228301056096e-06, 1.1073124986069124e-06, 1.158515960897698e-06, 1.210836096884575e-06, 1.2642703238720767e-06, 1.3188160674747873e-06, 1.3744707615813596e-06, 1.4312318483193268e-06, 1.4890967780177303e-06, 1.5480630091722988e-06, 1.6081280084100254e-06, 1.6692892504531072e-06, 1.7315442180841313e-06, 1.7948904021112077e-06, 1.8593253013333336e-06, 1.9248464225056154e-06, 1.9914512803042955e-06, 2.0591373972940495e-06, 2.1279023038931293e-06, 2.197743538339176e-06, 2.268658646655634e-06, 2.340645182620125e-06, 2.4137007077281353e-06, 2.4878227911626683e-06, 2.5630090097608654e-06, 2.6392569479788415e-06, 2.716564197862736e-06, 2.7949283590144014e-06, 2.8743470385599823e-06, 2.95481785111633e-06, 3.0363384187620724e-06, 3.1189063710021856e-06, 3.202519344741049e-06, 3.28717498424773e-06, 3.3728709411258156e-06, 3.459604874282899e-06, 3.547374449898983e-06, 3.6361773413974654e-06, 3.7260112294125795e-06, 3.816873801760773e-06, 3.90876275341009e-06, 4.00167578644882e-06, 4.095610610059285e-06, 4.190564940484307e-06, 4.28653650099973e-06, 4.38352302188419e-06, 4.481522240392369e-06, 4.580531900721878e-06, 4.680549753988123e-06, 4.781573558193721e-06, 4.8836010782011585e-06, 4.9866300857022644e-06, 5.090658359192633e-06, 5.195683683940815e-06, 5.30170385196468e-06, 5.408716661998235e-06, 5.516719919467321e-06, 5.625711436461783e-06, 5.735689031707556e-06]\n",
      "MSE is lowest when lambda= 0.0 , while MSE is  6.358327951982005e-30\n"
     ]
    }
   ],
   "source": [
    "# implement with Lasso regression\n",
    "# Reference:\n",
    "# Documentation of penalized (regularized) regression in statsmodels (Elastic Net)\n",
    "# https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.fit_regularized.html\n",
    "\n",
    "lambda_list = np.arange(0, 10.1, 0.1)\n",
    "mse_list = []\n",
    "L1_wt = 0 # 1 when LASSO fit, 0 when ridge fit\n",
    "\n",
    "# create statsmodels model\n",
    "model = sm.regression.linear_model.OLS(y, X)\n",
    "\n",
    "for i, j in enumerate(lambda_list):\n",
    "    result_LASSO = model.fit_regularized(L1_wt=L1_wt, alpha=float(j))\n",
    "    predict_list_original = result_LASSO.fittedvalues.tolist()\n",
    "    mse_list.append(mean_squared_error(y, predict_list_original))\n",
    "    \n",
    "minimum_value = np.min(mse_list)\n",
    "minimum_index_list = [i for i, j in enumerate(mse_list) if j == minimum_value]\n",
    "# print(mse_list)\n",
    "# print(minimum_index_list)\n",
    "print('MSE is lowest when lambda=', lambda_list[minimum_index_list[0]], \n",
    "      ', while MSE is ', mse_list[minimum_index_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricardo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "C:\\Users\\ricardo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\ricardo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.025962355545366744, tolerance: 0.004375\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8042175649346816e-08, 0.005060598623284526, 0.011413044904088484, 0.016982674333177468, 0.021946959192061678, 0.026550535818987607, 0.029970118305061612, 0.03275971048066953, 0.035409844293065734, 0.037854482632474346, 0.0405152657934808, 0.043095660487198754, 0.04561442886357404, 0.04810654162228002, 0.05065111570888456, 0.053301454133549295, 0.05610065265965889, 0.05890866338410395, 0.061692286310574655, 0.06458331880602426, 0.0671940994448531, 0.06967427627638731, 0.07141189554593406, 0.07298404303224633, 0.07462575791759056, 0.07633225391182907, 0.07807909009249739, 0.07972358031505103, 0.0814001339737144, 0.08292264861821966, 0.08449861454629204, 0.08607847726324733, 0.08767299451799905, 0.08927334633632046, 0.09057301733856421, 0.09189423475947128, 0.09311843169044773, 0.09418186557908466, 0.09527445226263331, 0.0963961598062578, 0.09729876382576781, 0.09819343358709276, 0.09908943805565577, 0.10000182183371757, 0.10093570332627239, 0.10189104542055004, 0.10286788951805854, 0.10386615930106859, 0.1048859297864563, 0.10525431454115416, 0.10558737630680545, 0.10592716651407107, 0.10626325980247944, 0.10660212563761062, 0.10694744606007762, 0.10729922106988049, 0.10765745066701918, 0.1080221348514937, 0.10839327362330406, 0.10877086698245023, 0.10915491492893224, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375, 0.109375]\n",
      "MSE is lowest when lambda= 0.0 , while MSE is  1.8042175649346816e-08\n"
     ]
    }
   ],
   "source": [
    "lambda_list = np.arange(0, 10.1, 0.1)\n",
    "mse_list = []\n",
    "\n",
    "for i, j in enumerate(lambda_list):\n",
    "    model_LASSO = linear_model.Lasso(alpha=j)\n",
    "    model_LASSO.fit(X, y)\n",
    "    predict_list_original = model_LASSO.predict(X).tolist()\n",
    "    mse_list.append(mean_squared_error(y, predict_list_original))\n",
    "    \n",
    "minimum_value = np.min(mse_list)\n",
    "minimum_index_list = [i for i, j in enumerate(mse_list) if j == minimum_value]\n",
    "print(mse_list)\n",
    "# print(minimum_index_list)\n",
    "print('MSE is lowest when lambda=', lambda_list[minimum_index_list[0]], \n",
    "      ', while MSE is ', mse_list[minimum_index_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricardo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:188: LinAlgWarning: Ill-conditioned matrix (rcond=6.20387e-19): result may not be accurate.\n",
      "  overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.033838863451482e-29, 3.353500642836017e-15, 1.3413977333153265e-14, 3.018139179043345e-14, 5.365570629196232e-14, 8.383688269858831e-14, 1.2072488287109303e-13, 1.6431966885565623e-13, 2.1462120200067746e-13, 2.7162944575138955e-13, 3.353443604374462e-13, 4.057659088981656e-13, 4.828940532479616e-13, 5.667287551954967e-13, 6.572699760756239e-13, 7.545176788480967e-13, 8.584718251207183e-13, 9.691323766036838e-13, 1.086499295266774e-12, 1.2105725430373916e-12, 1.3413520829864398e-12, 1.4788378746383338e-12, 1.6230298844319152e-12, 1.7739280681069781e-12, 1.9315323927827717e-12, 2.0958428180319683e-12, 2.266859305935204e-12, 2.444581820174215e-12, 2.6290103201614192e-12, 2.8201447697915394e-12, 3.0179851299383912e-12, 3.2225313629904385e-12, 3.4337834319415227e-12, 3.65174129626815e-12, 3.876404920095608e-12, 4.107774264207951e-12, 4.345849292018419e-12, 4.590629964413117e-12, 4.842116244154897e-12, 5.100308091133819e-12, 5.365205469735377e-12, 5.636808339227914e-12, 5.915116664742397e-12, 6.2001304054936526e-12, 6.491849526046612e-12, 6.790273988269824e-12, 7.095403749069178e-12, 7.407238779967425e-12, 7.7257790303079e-12, 8.051024474671913e-12, 8.382975066689192e-12, 8.721630772364168e-12, 9.066991552037544e-12, 9.41905736632653e-12, 9.777828180883419e-12, 1.0143303954376012e-11, 1.051548465318469e-11, 1.0894370234118433e-11, 1.1279960658228486e-11, 1.1672255894136689e-11, 1.2071255900045457e-11, 1.247696063522817e-11, 1.288937006615093e-11, 1.3308484152435318e-11, 1.3734302858610381e-11, 1.416682614272969e-11, 1.4606053967982593e-11, 1.505198630194607e-11, 1.5504623096642843e-11, 1.5963964321189217e-11, 1.6430009937188894e-11, 1.69027599032241e-11, 1.7382214185724906e-11, 1.7868372737213637e-11, 1.8361235532174722e-11, 1.8860802527590384e-11, 1.9367073683135423e-11, 1.98800489616506e-11, 2.039972832692393e-11, 2.0926111738592053e-11, 2.1459199159250478e-11, 2.1998990553183966e-11, 2.254548588270899e-11, 2.3098685103308247e-11, 2.365858818821651e-11, 2.422519508676192e-11, 2.4798505765400093e-11, 2.537852019594951e-11, 2.5965238321869682e-11, 2.6558660121502698e-11, 2.7158785552741585e-11, 2.7765614571342945e-11, 2.8379147146259968e-11, 2.899938323225519e-11, 2.962632279800976e-11, 3.0259965802877626e-11, 3.090031220980093e-11, 3.154736198085904e-11, 3.2201115075435996e-11, 3.2861571461766765e-11, 3.352873109257318e-11]\n",
      "MSE is lowest when lambda= 0.0 , while MSE is  3.033838863451482e-29\n"
     ]
    }
   ],
   "source": [
    "# implement with Ridge regression\n",
    "lambda_list = np.arange(0, 10.1, 0.1)\n",
    "mse_list = []\n",
    "\n",
    "for i, j in enumerate(lambda_list):\n",
    "    model_LASSO = linear_model.Ridge(alpha=j)\n",
    "    model_LASSO.fit(X, y)\n",
    "    predict_list_original = model_LASSO.predict(X).tolist()\n",
    "    mse_list.append(mean_squared_error(y, predict_list_original))\n",
    "    \n",
    "minimum_value = np.min(mse_list)\n",
    "minimum_index_list = [i for i, j in enumerate(mse_list) if j == minimum_value]\n",
    "print(mse_list)\n",
    "# print(minimum_index_list)\n",
    "print('MSE is lowest when lambda=', lambda_list[minimum_index_list[0]], \n",
    "      ', while MSE is ', mse_list[minimum_index_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricardo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  pixel_1470                     with p-value 3.91841e-14\n",
      "Add  pixel_2488                     with p-value 3.38413e-16\n",
      "Add  pixel_2271                     with p-value 6.02768e-11\n",
      "Add  pixel_1722                     with p-value 7.004e-08\n",
      "Add  pixel_555                      with p-value 1.31884e-07\n",
      "Add  pixel_1474                     with p-value 5.65748e-06\n",
      "Add  pixel_1386                     with p-value 8.20976e-06\n",
      "Add  pixel_1476                     with p-value 6.706e-07\n",
      "Add  pixel_1051                     with p-value 6.99533e-06\n",
      "Add  pixel_1561                     with p-value 1.92879e-05\n",
      "Add  pixel_202                      with p-value 1.4955e-05\n",
      "Add  pixel_133                      with p-value 1.23609e-05\n",
      "Add  pixel_186                      with p-value 6.96418e-12\n",
      "Add  pixel_1687                     with p-value 3.21537e-06\n",
      "Add  pixel_319                      with p-value 3.01682e-06\n",
      "Add  pixel_2393                     with p-value 7.13528e-05\n",
      "Add  pixel_1984                     with p-value 3.73409e-06\n",
      "Add  pixel_1325                     with p-value 6.84276e-05\n",
      "Add  pixel_343                      with p-value 9.94106e-05\n",
      "Add  pixel_325                      with p-value 0.000562402\n",
      "Add  pixel_1730                     with p-value 0.000406945\n",
      "Add  pixel_546                      with p-value 0.000298487\n",
      "Add  pixel_380                      with p-value 4.57692e-05\n",
      "Add  pixel_183                      with p-value 0.000308109\n",
      "Add  pixel_95                       with p-value 3.63205e-05\n",
      "Add  pixel_1180                     with p-value 3.31484e-05\n",
      "Add  pixel_2158                     with p-value 0.000121498\n",
      "Add  pixel_2162                     with p-value 4.16994e-05\n",
      "Add  pixel_2168                     with p-value 8.06627e-05\n",
      "Add  pixel_1936                     with p-value 0.000889671\n",
      "Add  pixel_429                      with p-value 0.000837327\n",
      "Add  pixel_845                      with p-value 0.000697652\n",
      "Add  pixel_1701                     with p-value 0.00106987\n",
      "Add  pixel_427                      with p-value 0.00217797\n",
      "Add  pixel_1846                     with p-value 0.00183714\n",
      "Add  pixel_1976                     with p-value 0.000389739\n",
      "Add  pixel_1565                     with p-value 0.0027571\n",
      "Add  pixel_1796                     with p-value 0.0042983\n",
      "Add  pixel_2120                     with p-value 0.000574771\n",
      "Add  pixel_288                      with p-value 0.00418911\n",
      "Add  pixel_96                       with p-value 0.00568254\n",
      "Add  pixel_97                       with p-value 0.00430898\n",
      "Add  pixel_11                       with p-value 0.00332272\n",
      "Add  pixel_135                      with p-value 0.00183605\n",
      "Add  pixel_1929                     with p-value 0.00266105\n",
      "Add  pixel_1000                     with p-value 0.00262142\n",
      "Add  pixel_2207                     with p-value 0.000862107\n",
      "Add  pixel_2021                     with p-value 0.00276112\n",
      "Add  pixel_2561                     with p-value 0.0030418\n",
      "Add  pixel_884                      with p-value 0.00615057\n",
      "Add  pixel_1343                     with p-value 0.00655036\n",
      "Add  pixel_492                      with p-value 0.00926238\n",
      "Add  pixel_574                      with p-value 0.00303123\n",
      "Add  pixel_1005                     with p-value 0.00151712\n",
      "Add  pixel_1152                     with p-value 0.0020989\n",
      "Add  pixel_606                      with p-value 0.00180389\n",
      "Add  pixel_1588                     with p-value 0.00472962\n",
      "Add  pixel_2241                     with p-value 0.00267524\n",
      "Add  pixel_2034                     with p-value 0.00628596\n",
      "Add  pixel_2341                     with p-value 0.00209227\n",
      "Add  pixel_509                      with p-value 0.00983602\n",
      "Add  pixel_1105                     with p-value 0.00472625\n",
      "Backward Selection\n",
      "Drop pixel_2162                     with p-value 0.91927\n",
      "Drop pixel_186                      with p-value 0.489168\n",
      "Drop pixel_1687                     with p-value 0.211977\n",
      "Drop pixel_1051                     with p-value 0.203061\n",
      "Drop pixel_1470                     with p-value 0.0701448\n",
      "Drop pixel_2488                     with p-value 0.0676052\n",
      "Drop pixel_380                      with p-value 0.0122945\n",
      "Drop pixel_884                      with p-value 0.0111691\n",
      "['pixel_2271', 'pixel_1722', 'pixel_555', 'pixel_1474', 'pixel_1386', 'pixel_1476', 'pixel_1561', 'pixel_202', 'pixel_133', 'pixel_319', 'pixel_2393', 'pixel_1984', 'pixel_1325', 'pixel_343', 'pixel_325', 'pixel_1730', 'pixel_546', 'pixel_183', 'pixel_95', 'pixel_1180', 'pixel_2158', 'pixel_2168', 'pixel_1936', 'pixel_429', 'pixel_845', 'pixel_1701', 'pixel_427', 'pixel_1846', 'pixel_1976', 'pixel_1565', 'pixel_1796', 'pixel_2120', 'pixel_288', 'pixel_96', 'pixel_97', 'pixel_11', 'pixel_135', 'pixel_1929', 'pixel_1000', 'pixel_2207', 'pixel_2021', 'pixel_2561', 'pixel_1343', 'pixel_492', 'pixel_574', 'pixel_1005', 'pixel_1152', 'pixel_606', 'pixel_1588', 'pixel_2241', 'pixel_2034', 'pixel_2341', 'pixel_509', 'pixel_1105']\n",
      "Length: 54\n"
     ]
    }
   ],
   "source": [
    "# implement with stepwise regression\n",
    "def forward_regression(X, y,\n",
    "                       threshold_in,\n",
    "                       verbose):\n",
    "    print('Forward Selection')\n",
    "    initial_list = []\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "def backward_regression(X, y,\n",
    "                           threshold_out,\n",
    "                           verbose=False):\n",
    "    print('Backward Selection')\n",
    "    included=list(X.columns)\n",
    "    while True:\n",
    "        changed=False\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "# perform stepwise regression (with forward selection)\n",
    "included_list = forward_regression(X, y, 0.01, True)\n",
    "# perform stepwise regression (with backward selection)\n",
    "X = pd.DataFrame(X[[j for i, j in enumerate(included_list)]])\n",
    "included_list = backward_regression(X, y, 0.01, True)\n",
    "print(included_list)\n",
    "print('Length:', len(included_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# interpret the result of Lasso\n",
    "param_data_LASSO = pd.DataFrame({\n",
    "    'Pixel':result_LASSO.params.index.tolist(),\n",
    "    'Params':result_LASSO.params.values.tolist()\n",
    "})\n",
    "\n",
    "param_data_LASSO = param_data_LASSO.sort_values(by=['Params'], ascending=False)\n",
    "chosen_vars_LASSO = param_data_LASSO.iloc[0:54, 0].values.tolist()\n",
    "\n",
    "shared_var_list = []\n",
    "\n",
    "for i, j in enumerate(chosen_vars_LASSO):\n",
    "    if j in included_list:\n",
    "        shared_var_list.append(j)\n",
    "\n",
    "# print(len(shared_var_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chosen_vars_LASSO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-7080eae4cb13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpixel_list_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# transform back to pixel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchosen_vars_LASSO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m46\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chosen_vars_LASSO' is not defined"
     ]
    }
   ],
   "source": [
    "# (b)\n",
    "# Interpret and plot the result\n",
    "pixel_list_number = []\n",
    "pixel_list_x = []\n",
    "pixel_list_y = []\n",
    "# transform back to pixel\n",
    "for i, j in enumerate(chosen_vars_LASSO):\n",
    "    value = int(j[6:])\n",
    "    row = value / 46 - 1\n",
    "    column = value % 46 - 1\n",
    "    pixel_list_number.append(value)\n",
    "    pixel_list_x.append(row)\n",
    "    pixel_list_y.append(column)\n",
    "    file = \"./data/ORL_Faces_Classified/0/1_1.png\"\n",
    "    sample = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    for i, j in enumerate(pixel_list_x):\n",
    "        x_value = int(j - 1)\n",
    "        y_value = int(pixel_list_y[i] - 1)\n",
    "        sample[x_value, y_value] = 0\n",
    "# cv2.imwrite( \"./sample.png\", sample)\n",
    "imgplot = plt.imshow(sample, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "<img src='./picture_source/HW_4_3.PNG' width='500px' align='middle'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.93954312 0.06045688]\n",
      "\n",
      "[[ 0.83849224 -0.54491354]\n",
      " [ 0.54491354  0.83849224]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def PCA_decomposition(X, isCorrMX):\n",
    "    # Reference: https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/\n",
    "    # calculate mean of the array\n",
    "    X_mean = np.mean(X.T, axis=1)\n",
    "    # center the values\n",
    "    X_center = X - X_mean\n",
    "    # check if use Correlation Matrix\n",
    "    if isCorrMX == True:\n",
    "        X_covariance = np.corrcoef(X_center.T)\n",
    "    else:\n",
    "        X_covariance = np.cov(X_center.T)\n",
    "    # calculate eigenvalues and eigenvectors\n",
    "    # https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(X_covariance)\n",
    "    # \n",
    "    X_project = eigenvectors.T.dot(X_center.T).T\n",
    "    return eigenvalues, eigenvectors, X_project\n",
    "\n",
    "X = np.array([[1, 1], [0, 1], [-1, 0], [3, 3], [4, 3], [5, 4]])\n",
    "\n",
    "# eigenvalues, eigenvectors, X_project = PCA_decomposition(X, True)\n",
    "eigenvalues, eigenvectors, X_project = PCA_decomposition(X, False)\n",
    "print(eigenvalues)\n",
    "print()\n",
    "print(eigenvectors)\n",
    "print()\n",
    "# print(X_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4\n",
    "<img src='./picture_source/HW_4_4.PNG' width='500px' align='middle'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORL_data = pd.read_csv('./data/ORL_data.csv').iloc[:,:-1]\n",
    "\n",
    "ORL_data_array = np.transpose(ORL_data.to_numpy())\n",
    "# print(ORL_data_array.shape)\n",
    "eigenvalues, eigenvectors, X_project = PCA_decomposition(ORL_data_array, False)\n",
    "# print(eigenvalues.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate explainable ratio of each pricipal components\n",
    "explainable_ratio_list = []\n",
    "for i in range(eigenvalues.shape[0]):\n",
    "    eigenvalues_totals = np.sum(eigenvalues)\n",
    "    ratio = eigenvalues[i] / eigenvalues_totals\n",
    "    explainable_ratio_list.append(ratio)\n",
    "    \n",
    "# print(explainable_ratio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50%: 2 pricipal components needed.\n",
      "60%: 3 pricipal components needed.\n",
      "70%: 6 pricipal components needed.\n",
      "80%: 15 pricipal components needed.\n",
      "90%: 47 pricipal components needed.\n",
      "[2, 3, 6, 15, 47]\n"
     ]
    }
   ],
   "source": [
    "# calculate how many principal components needed to explain 50, 60, 70, 80, 90% of total variance\n",
    "total_explainable_ratio = 0\n",
    "components_needed_list = []\n",
    "\n",
    "for i, j in enumerate(explainable_ratio_list):\n",
    "    total_explainable_ratio += j\n",
    "    if total_explainable_ratio >= 0.9:\n",
    "        if len(components_needed_list) < 5: \n",
    "            components_needed_list.append(i+1) \n",
    "            print('90%:', str(i+1), 'pricipal components needed.')\n",
    "        break\n",
    "    elif total_explainable_ratio >= 0.8:\n",
    "        if len(components_needed_list) < 4: \n",
    "            components_needed_list.append(i+1) \n",
    "            print('80%:', str(i+1), 'pricipal components needed.')\n",
    "    elif total_explainable_ratio >= 0.7:\n",
    "        if len(components_needed_list) < 3: \n",
    "            components_needed_list.append(i+1) \n",
    "            print('70%:', str(i+1), 'pricipal components needed.')\n",
    "    elif total_explainable_ratio >= 0.6:\n",
    "        if len(components_needed_list) < 2: \n",
    "            components_needed_list.append(i+1) \n",
    "            print('60%:', str(i+1), 'pricipal components needed.')\n",
    "    elif total_explainable_ratio >= 0.5:\n",
    "        if len(components_needed_list) < 1: \n",
    "            components_needed_list.append(i+1) \n",
    "            print('50%:', str(i+1), 'pricipal components needed.')\n",
    "            \n",
    "print(components_needed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2576,)\n"
     ]
    }
   ],
   "source": [
    "ORL_data = pd.read_csv('./data/ORL_data.csv').iloc[:,:-1]\n",
    "\n",
    "ORL_data_array = np.transpose(ORL_data.to_numpy())\n",
    "# print(ORL_data_array.shape)\n",
    "eigenvalues, eigenvectors, X_project = PCA_decomposition(ORL_data_array, False)\n",
    "# print(eigenvalues.shape)\n",
    "# print(X_project.shape)\n",
    "\n",
    "pc1_X_project = X_project[:, 0]\n",
    "print(pc1_X_project.shape)\n",
    "# print(pc1_X_project[0])\n",
    "min_pc1 = np.min(pc1_X_project)\n",
    "range_pc1 = np.max(pc1_X_project) - np.min(pc1_X_project)\n",
    "\n",
    "for i, j in enumerate(pc1_X_project):\n",
    "    pc1_X_project[i] = 255 * ((j - min_pc1) / range_pc1)\n",
    "    \n",
    "# print(pc1_X_project)\n",
    "# print(pc1_X_project.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixel_list_number = []\n",
    "pixel_list_x = []\n",
    "pixel_list_y = []\n",
    "\n",
    "for i, j in enumerate(pc1_X_project.tolist()):\n",
    "    value = (i+1)\n",
    "    row = value / 46\n",
    "    column = value % 46 - 1\n",
    "    pixel_list_number.append(value)\n",
    "    pixel_list_x.append(row)\n",
    "    pixel_list_y.append(column)\n",
    "    \n",
    "\n",
    "sample = np.zeros(shape=(56, 46))\n",
    "for i, j in enumerate(pixel_list_x):\n",
    "    x_value = int(j - 1)\n",
    "    y_value = int(pixel_list_y[i] - 1)\n",
    "    sample[x_value, y_value] = pc1_X_project[i]\n",
    "\n",
    "imgplot = plt.imshow(sample, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KerasGPU",
   "language": "python",
   "name": "kerasgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
