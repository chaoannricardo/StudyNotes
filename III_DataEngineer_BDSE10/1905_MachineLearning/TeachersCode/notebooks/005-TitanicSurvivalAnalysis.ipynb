{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本筆記拿鐵達尼號資料集來練習建模。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們將用Scikit-learn和Keras來建立一些基本的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [將檔案存為Pandas DataFrame](#%E5%B0%87%E6%AA%94%E6%A1%88%E5%AD%98%E7%82%BAPandas-DataFrame)\n",
    "\n",
    "* [空直填補](#%E7%A9%BA%E7%9B%B4%E5%A1%AB%E8%A3%9C)\n",
    "\n",
    "* [用scikit-learn建立模型：Decision Tree](#%E7%94%A8scikit-learn%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B%EF%BC%9ADecision-Tree)\n",
    "\n",
    "* [用scikit-learn建立模型：Random Forest](#%E7%94%A8scikit-learn%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B%EF%BC%9ARandom-Forest)\n",
    "* [scikit-learn練習：使用logistic regression來分資料，並輸出分類報告](#scikit-learn%E7%B7%B4%E7%BF%92%EF%BC%9A%E4%BD%BF%E7%94%A8logistic-regression%E4%BE%86%E5%88%86%E8%B3%87%E6%96%99%EF%BC%8C%E4%B8%A6%E8%BC%B8%E5%87%BA%E5%88%86%E9%A1%9E%E5%A0%B1%E5%91%8A%E3%80%82)\n",
    "* [用Keras建立模型：Logistic Regression](#%E7%94%A8Keras%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B%EF%BC%9ALogistic-Regression)\n",
    "* [用Keras建立模型：Multilayer Perceptron + BatchNorm](#%E7%94%A8Keras%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B%EF%BC%9AMultilayer-Perceptron)\n",
    "* [用Keras建立模型：Multilayer Perceptron + Dropout](#%E7%94%A8Keras%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B%EF%BC%9AMultilayer-Perceptron-+-Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a temporary workout. I replace data in several dataframes, which leads to some warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將檔案存為Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../datasets/titanic/titanic_train.csv\") # 輸入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回到頂部](#%E6%9C%AC%E7%AD%86%E8%A8%98%E6%8B%BF%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E8%B3%87%E6%96%99%E9%9B%86%E4%BE%86%E7%B7%B4%E7%BF%92%E5%BB%BA%E6%A8%A1%E3%80%82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空直填補"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap=sns.light_palette(\"navy\", reverse=False)\n",
    "sns.heatmap(data.isnull().astype(np.int8),yticklabels=False,cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.factorplot(x=\"Pclass\",y=\"Age\",data=data,kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.factorplot(x=\"Pclass\",y=\"Age\",hue=\"Sex\",data=data,kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.factorplot(x=\"Sex\",y=\"Age\",data=data,kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.factorplot(x=\"Embarked\",y=\"Age\",data=data,kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "決定用Pclass的中位數來填補Age之空值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\"Pclass\").median()[\"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataClean(df):\n",
    "    # 資料整理。將空值填補。\n",
    "    \n",
    "    nanIndexes={}\n",
    "    groups=df.groupby(\"Pclass\")\n",
    "    for name,group in groups:\n",
    "        nanIndexes[name]=group[\"Age\"][group[\"Age\"].isnull()].index\n",
    "    data[\"Age\"][nanIndexes[1]]=37\n",
    "    data[\"Age\"][nanIndexes[2]]=29\n",
    "    data[\"Age\"][nanIndexes[3]]=24\n",
    "    \n",
    "    idxEmbarked=df[df[\"Embarked\"].isnull()].index\n",
    "    idxDrop=idxEmbarked\n",
    "    df=df.drop(index=idxDrop)\n",
    "\n",
    "    df=df.drop(\n",
    "        columns=[\"Name\",\"PassengerId\",\"Cabin\",\"Ticket\"])\n",
    "\n",
    "    df[\"famSize\"]=df[\"SibSp\"]+df[\"Parch\"]\n",
    "    df[\"Kid\"]=df[\"Age\"].apply(lambda x: 1 if x<12 else 0)\n",
    "    df[\"Pclass\"]=df[\"Pclass\"].astype(\"object\")\n",
    "    df[\"Sex\"]=df[\"Sex\"].apply(lambda x:0 if \"female\" in x else 1)\n",
    "    \n",
    "    for col in [\"Age\",\"Fare\"]:\n",
    "        df[col]=( df[col]-df[col].mean() ) / df[col].std()\n",
    "    \n",
    "    df=pd.get_dummies(df)\n",
    "    \n",
    "    print(\"檢查資料整理前是否存在空值:\\n\",df.isnull().sum(),\"\\n\") # 檢查空值情形。\n",
    "    return df\n",
    "\n",
    "def trainTestValSplit(df):\n",
    "    # 將資料切分為訓練(70%),測試(15%)和驗證(15%)三份。\n",
    "    train=df.sample(frac=0.7)\n",
    "    test=df.drop( train.index )\n",
    "    val=test.sample(frac=0.5)\n",
    "    test=test.drop( val.index)\n",
    "    return train,test,val\n",
    "\n",
    "def dfXYSplit(df,targetName):\n",
    "    # 將特徵和目標變數切成兩份資料。\n",
    "    \n",
    "    dfX=df.drop(columns=targetName)\n",
    "    dfY=df[targetName]\n",
    "    \n",
    "    return dfX,dfY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../datasets/titanic/titanic_train.csv\") # 輸入資料\n",
    "data=dataClean(data)\n",
    "print(data.info() )\n",
    "data.head(5)\n",
    "\n",
    "train,test,val=trainTestValSplit(data)\n",
    "\n",
    "trainX,trainY=dfXYSplit(train,\"Survived\")\n",
    "testX,testY=dfXYSplit(test,\"Survived\")\n",
    "valX,valY=dfXYSplit(val,\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料整理完畢，可以開始建立模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回到頂部](#%E6%9C%AC%E7%AD%86%E8%A8%98%E6%8B%BF%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E8%B3%87%E6%96%99%E9%9B%86%E4%BE%86%E7%B7%B4%E7%BF%92%E5%BB%BA%E6%A8%A1%E3%80%82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 用scikit-learn建立模型：Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Decision Tree: http://scikit-learn.org/stable/modules/tree.html#mathematical-formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=tree.DecisionTreeClassifier()\n",
    "model=clf.fit(trainX,trainY)\n",
    "\n",
    "testPredY=model.predict(testX)\n",
    "valPredY=model.predict(valX)\n",
    "\n",
    "print( classification_report(testY,testPredY) )\n",
    "print( classification_report(valY,valPredY) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble.forest import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回到頂部](#%E6%9C%AC%E7%AD%86%E8%A8%98%E6%8B%BF%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E8%B3%87%E6%96%99%E9%9B%86%E4%BE%86%E7%B7%B4%E7%BF%92%E5%BB%BA%E6%A8%A1%E3%80%82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 用scikit-learn建立模型：Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forest: https://www.youtube.com/watch?v=3kYujfDgmNk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ```bootstrap=True``` ->要抽樣本\n",
    "* ```n_jobs=1``` ->記得要改 ```n_jobs=-1```, 使用所有的CPU核心\n",
    "* ```oob_score``` -> out of bag score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=clf.fit(trainX,trainY)\n",
    "\n",
    "testPredY=model.predict(testX)\n",
    "valPredY=model.predict(valX)\n",
    "\n",
    "print( classification_report(testY,testPredY) )\n",
    "print( classification_report(valY,valPredY) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面是錯的.不要把資料切三分丟給random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 什麼是OOB score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為做隨機森林,驗證資料(validation data)不需要存在,故我們把驗證資料和訓練資料合併."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainXNew = np.concatenate([trainX,valX],axis=0)\n",
    "trainYNew = np.concatenate([trainY,valY],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驗證資料有沒有合併成功:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert valX.shape[0]+trainX.shape[0] == trainXNew.shape[0]\n",
    "assert valY.shape[0]+trainY.shape[0] == trainYNew.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(oob_score=True)\n",
    "model=clf.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn練習：使用logistic regression來分資料，並輸出分類報告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 補足以下程式碼\n",
    "from sklearn.linear_model.... import LogisticRegression\n",
    "clf=LogisticRegression()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回到頂部](#%E6%9C%AC%E7%AD%86%E8%A8%98%E6%8B%BF%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E8%B3%87%E6%96%99%E9%9B%86%E4%BE%86%E7%B7%B4%E7%BF%92%E5%BB%BA%E6%A8%A1%E3%80%82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用Keras建立模型：Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense,Dropout,BatchNormalization\n",
    "from keras.optimizers import RMSprop,SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(1, input_shape=(trainX.shape[1],),activation='sigmoid') ) \n",
    "# initiate RMSprop optimizer\n",
    "#opt = RMSprop(lr=0.05, decay=1e-6)\n",
    "opt = SGD(lr=0.05)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(trainX.values,trainY.values,epochs=20, validation_data=( valX.values, valY.values ) )\n",
    "\n",
    "#畫出訓練過程\n",
    "plt.plot(history.history['acc'],ms=5,marker='o',label='accuracy')\n",
    "plt.plot(history.history['val_acc'],ms=5,marker='o',label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回到頂部](#%E6%9C%AC%E7%AD%86%E8%A8%98%E6%8B%BF%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E8%B3%87%E6%96%99%E9%9B%86%E4%BE%86%E7%B7%B4%E7%BF%92%E5%BB%BA%E6%A8%A1%E3%80%82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用Keras建立模型：Multilayer Perceptron + BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reference: \n",
    "\n",
    "  Rmsprop: http://ruder.io/optimizing-gradient-descent/\n",
    "\n",
    "  簡單來說，是Gradient Descent的改良。相較於Gradient Descent是針對每一個網路參數($w_1,w_2,...,w_n$)使用相同的learning rate ($lr$)，RMSPROP則是能夠使得每一個每一個參數($w_1,w_2,...,w_n$)去擁有不同的learning rate ($lr_1, lr_2,...,lr_n$)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reference: \n",
    "\n",
    "  BatchNormalization: https://zh-tw.coursera.org/learn/deep-neural-network/lecture/81oTm/why-does-batch-norm-work\n",
    "\n",
    "  簡單來說，網路較內層的參數若於學習過程中一直改變，會導致較外層的輸出分佈一直產生變化。這件事情將不利於網路的訓練。我們若將這個分佈重新shift, 就可以加速網路訓練。(若看不懂這幾句話，請見以上連結，裡面有比較詳細的說明。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(50, input_shape=(trainX.shape[1],),activation='relu') )\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(50) )\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, input_shape=(trainX.shape[1],),activation='sigmoid') ) \n",
    "# initiate RMSprop optimizer\n",
    "opt = RMSprop(lr=0.01, decay=1e-5)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(trainX.values,trainY.values,epochs=30,\n",
    "                  validation_data=( valX.values, valY.values ), batch_size=batch_size,verbose=1)\n",
    "\n",
    "#畫出訓練過程\n",
    "plt.plot(history.history['acc'],ms=5,marker='o',label='accuracy')\n",
    "plt.plot(history.history['val_acc'],ms=5,marker='o',label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回到頂部](#%E6%9C%AC%E7%AD%86%E8%A8%98%E6%8B%BF%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E8%B3%87%E6%96%99%E9%9B%86%E4%BE%86%E7%B7%B4%E7%BF%92%E5%BB%BA%E6%A8%A1%E3%80%82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用Keras建立模型：Multilayer Perceptron + Dropout \n",
    "\n",
    "添加Dropout layer可減少Overfitting。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dropout layer: https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/dropout_layer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(50, input_shape=(trainX.shape[1],),activation='relu') )\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(50) )\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(1, input_shape=(trainX.shape[1],),activation='sigmoid') ) \n",
    "# initiate RMSprop optimizer\n",
    "opt = RMSprop(lr=0.01, decay=1e-5)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(trainX.values,trainY.values,epochs=30,\n",
    "                  validation_data=( valX.values, valY.values ), batch_size=batch_size,verbose=1)\n",
    "\n",
    "#畫出訓練過程\n",
    "plt.plot(history.history['acc'],ms=5,marker='o',label='accuracy')\n",
    "plt.plot(history.history['val_acc'],ms=5,marker='o',label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回到頂部](#%E6%9C%AC%E7%AD%86%E8%A8%98%E6%8B%BF%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E8%B3%87%E6%96%99%E9%9B%86%E4%BE%86%E7%B7%B4%E7%BF%92%E5%BB%BA%E6%A8%A1%E3%80%82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 輸出成csv, 提交至Kaggle:\n",
    "# subm=np.vstack( (dfTest[\"PassengerId\"].values,testY) ).T\n",
    "# subm=pd.DataFrame(subm,columns=[\"PassengerId\",\"Survived\"])\n",
    "# subm.to_csv(\"~/Dropbox/Learning/submissionLogistic.csv\",index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
