{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import chardet\n",
    "import numpy as np\n",
    "import math\n",
    "# coding=utf-8\n",
    "\n",
    "#查詢目錄位置\n",
    "print( os.getcwd()  )\n",
    "\n",
    "Folder_Path = \"Z:/VPA-13C OAD Data/1_NG\"   #要拼接的文件夾及其完整路徑，注意不要包含中文\n",
    "SaveFile_Path = 'C:/Users/1907075/Project/VAS_Project_Python'    #拼接後要保存的文件路徑\n",
    "SaveFile_Name = 'all_0720_NG.csv'                                     #合並後要保存的文件名\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判斷編碼型態\n",
    "\n",
    "def find_encoding(fname):\n",
    "    r_file = open(fname, 'rb').read() # 'b', meaning 'binary'.\n",
    "    result = chardet.detect(r_file) # chardet.detect() 函式就可以偵測字串「最有可能」的編碼\n",
    "    charenc = result['encoding'] #識別編碼\n",
    "    return charenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料清理，增加資料\n",
    "def data_Cleaning(dfname,filename):\n",
    "    filename= file_list[0]  #取檔名\n",
    "\n",
    "    dfname.insert(1,'filename' ,filename ) #插入檔名\n",
    "    #dfname[np.isnan(dfname['Vacuum Data_VG001_Exponent'])]=0\n",
    "    \n",
    "    # Vacuum Align System (真空貼合系統)\n",
    "    # 換算壓力值公式 : log10(Mantissa*10^Exponent)，總共7組 gauge pressure sensor ( Mantissa(尾數) ; Exponent(指數))\n",
    "    dfname.insert(2,'VG001' ,np.log10(dfname.loc[:,'Vacuum Data_VG001_Mantissa']*(np.power(10.,(dfname['Vacuum Data_VG001_Exponent']) )  )  ))   #插入VG001\n",
    "    dfname.insert(3,'VG002' ,np.log10(dfname['Vacuum Data_VG002_Mantissa']*(np.power(10.,(dfname['Vacuum Data_VG002_Exponent']) )  )  ))   #插入VG002\n",
    "    dfname.insert(4,'VG003' ,np.log10(dfname['Vacuum Data_VG003_Mantissa']*(np.power(10.,(dfname['Vacuum Data_VG003_Exponent']) )  )  ))   #插入VG003    \n",
    "    dfname.insert(5,'VG111' ,np.log10(dfname['Vacuum Data_VG111_Mantissa']*(np.power(10.,(dfname['Vacuum Data_VG111_Exponent']) )  )  ))   #插入VG111        \n",
    "    dfname.insert(6,'VG921' ,np.log10(dfname['Vacuum Data_VG921_Mantissa']*(np.power(10.,(dfname['Vacuum Data_VG921_Exponent']) )  )  ))   #插入VG921        \n",
    "    dfname.insert(7,'VG922' ,np.log10(dfname['Vacuum Data_VG922_Mantissa']*(np.power(10.,(dfname['Vacuum Data_VG923_Exponent']) )  )  ))   #插入VG922        \n",
    "    dfname.insert(8,'VG923' ,np.log10(dfname['Vacuum Data_VG923_Mantissa']*(np.power(10.,(dfname['Vacuum Data_VG922_Exponent']) )  )  ))   #插入VG923        \n",
    "    \n",
    "    #取代上午/下午\n",
    "      # df.loc[df.First_name != 'Bill', 'name_match'] = 'Mis-Match'  \n",
    "    dfname.loc[dfname.DateTime.str.contains(\"上午\") , 'DateTime24'] =  dfname.DateTime.str.replace('上午','') +\"AM\" \n",
    "    dfname.loc[dfname.DateTime.str.contains(\"下午\") , 'DateTime24'] =  dfname.DateTime.str.replace('下午','') +\"PM\"        \n",
    "\n",
    "    #轉換 DateTime 24小時制\n",
    "    dfname.DateTime24 = pd.to_datetime( dfname.DateTime24 ).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "     # 移動排序 DateTime24\n",
    "    cols = list(dfname)\n",
    "    cols.insert(0,cols.pop(cols.index('DateTime24')))\n",
    "    dfname = dfname.loc[:,cols]\n",
    "\n",
    "   # dfname['new_DateTime']=dfname.new_DateTime(1)\n",
    "\n",
    "    # Row 排序\n",
    "    #dfname.sort(['DateTime'], ascending=[1])\n",
    "    dfname.sort_values(by=['filename', 'DateTime24'] )  \n",
    "    \n",
    "    #  刪除重複row    \n",
    "    dfname.drop_duplicates( ['filename', 'DateTime24' ] , keep = 'first' ,inplace=True)   \n",
    "    \n",
    "    # 插入rownum\n",
    "    dfname.insert(1,'rownum' , np.arange(len(dfname)) ) \n",
    "    \n",
    "    return dfname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [Vacuum Data_VG001_Mantissa] is not in the [columns]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1505\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1506\u001b[1;33m                     \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1507\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1500\u001b[0m                                .format(key=key,\n\u001b[1;32m-> 1501\u001b[1;33m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [Vacuum Data_VG001_Mantissa] is not in the [columns]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-bff4daf1b084>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#將讀取的第一個CSV文件寫入合並後的文件保存\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdfClean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_Cleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mdfClean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSaveFile_Path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mSaveFile_Name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf_8\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 儲存 Column Name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-13a4cda2505a>\u001b[0m in \u001b[0;36mdata_Cleaning\u001b[1;34m(dfname, filename)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Vacuum Align System (真空貼合系統)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# 換算壓力值公式 : log10(Mantissa*10^Exponent)，總共7組 gauge pressure sensor ( Mantissa(尾數) ; Exponent(指數))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdfname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'VG001'\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Vacuum Data_VG001_Mantissa'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Vacuum Data_VG001_Exponent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#插入VG001\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdfname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'VG002'\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Vacuum Data_VG002_Mantissa'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Vacuum Data_VG002_Exponent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#插入VG002\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdfname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'VG003'\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Vacuum Data_VG003_Mantissa'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Vacuum Data_VG003_Exponent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#插入VG003\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1365\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 991\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m                 \u001b[1;31m# we have yielded a scalar ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1625\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1512\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m                 \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n\u001b[0;32m   1500\u001b[0m                                .format(key=key,\n\u001b[1;32m-> 1501\u001b[1;33m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [Vacuum Data_VG001_Mantissa] is not in the [columns]'"
     ]
    }
   ],
   "source": [
    "#修改當前工作目錄\n",
    "os.chdir(Folder_Path)\n",
    "#將該文件夾下的所有文件名存入一個列表\n",
    "file_list = os.listdir()\n",
    " \n",
    "#讀取第一個CSV文件並包含表頭\n",
    "my_encoding = find_encoding(Folder_Path +'\\\\'+ file_list[0])\n",
    "df = pd.read_csv(Folder_Path +'\\\\'+ file_list[0], encoding=my_encoding)   #編碼默認UTF-8，若亂碼自行更改\n",
    "\n",
    "#將讀取的第一個CSV文件寫入合並後的文件保存\n",
    "dfClean=data_Cleaning(df,file_list[0])\n",
    "dfClean.to_csv(SaveFile_Path+'\\\\'+ SaveFile_Name,encoding=\"utf_8\",index=False)  # 儲存 Column Name\n",
    "    \n",
    "#循環遍歷列表中各個CSV文件名，並追加到合並後的文件\n",
    "for i in range(1,len(file_list)):\n",
    "    # 讀檔\n",
    "    df = pd.read_csv(Folder_Path + '\\\\'+ file_list[i], encoding=my_encoding)  \n",
    "    \n",
    "    # 清洗資料\n",
    "    dfClean=data_Cleaning(df,file_list[i])\n",
    "        \n",
    "   \n",
    "    # Save All\n",
    "    dfClean.to_csv(SaveFile_Path+'\\\\'+ SaveFile_Name,encoding=\"utf_8\",index=False, header=False, mode='a+')  # header=False (不儲存Column Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data using pandas build in read csv function\n",
    "#df_city_time_series = pd.read_csv('../input/City_time_series.csv',parse_dates=['Date'])\n",
    "df_city_time_series = dfClean \n",
    "# drop null values in ZHVIPerSqft_AllHomes because we are interested in this column\n",
    "df_city_time_series = df_city_time_series.dropna(subset=['VG001'])\n",
    "# print the head of our data set\n",
    "df_city_time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series data source: fpp pacakge in R.\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(r'C:\\Users\\bwich\\Google_Cloud\\AIA_Project-VAS\\Data\\all_0720.csv', parse_dates=['rownum'], index_col='rownum')\n",
    "#df=dfClean\n",
    "# Draw Plot\n",
    "def plot_df(df, x, y, title=\"\", xlabel='rownum', ylabel='VG001', dpi=1500):\n",
    "    plt.figure(figsize=(16,5), dpi=dpi)\n",
    "    plt.plot(x, y, color='tab:red')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "\n",
    "plot_df(df, x=df.index, y=df.VG001, title='VAS Serial.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(20,4), dpi=100)\n",
    "#pd.read_csv(r'C:\\Users\\bwich\\Google_Cloud\\AIA_Project-VAS\\Data\\all_0720.csv', parse_dates=['rownum'], index_col='rownum').plot(title='Trend Only', legend=False, ax=axes[0])\n",
    "\n",
    "pd.read_csv(r'C:\\Users\\bwich\\Google_Cloud\\AIA_Project-VAS\\Data\\all_0720.csv', parse_dates=['rownum'], index_col='rownum').plot(title='Seasonality Only', legend=False, ax=axes[1])\n",
    "\n",
    "#pd.read_csv(r'C:\\Users\\bwich\\Google_Cloud\\AIA_Project-VAS\\Data\\all_0720.csv', parse_dates=['rownum'], index_col='rownum').plot(title='Trend and Seasonality', legend=False, ax=axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "cc =  pd.read_csv(r'C:\\Users\\bwich\\Google_Cloud\\AIA_Project-VAS\\Data\\all_0720.csv', parse_dates=['rownum'], index_col='rownum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data check. \n",
    "\n",
    "cc.head()\n",
    "cc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I observed an conflict in the name 'class'. Therefore, I have changed the name from class to category\n",
    "\n",
    "#cc= cc.rename(columns={'Class': 'Category'})\n",
    "cc[\"Category\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_obs = cc.loc[cc.Category==0]    #Data frame with normal observation\n",
    "ano_obs = cc.loc[cc.Category==1]    #Data frame with anomalous observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The given dataframe 'cc' is divided into three sets\n",
    "\n",
    "# Training set: train_features\n",
    "\n",
    "# Test observations/features: X_test\n",
    "\n",
    "# Test labels: Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一旦類SVM訓練只有一個類的觀察。 在這種情況下，通過首次200,000次正常交易觀察來訓練算法。 剩下的觀察與異常觀察合併以創建測試集。\n",
    "# Once class SVM is trained with the observations of only one class. In this case, the algorithm is trained with first 200,000 observation of normal transactions. The remaining observations are merged with the anomalous observation to create a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once class SVM is trained with the observations of only one class. In this case, the algorithm is trained with \n",
    "# first 200,000 observation of normal transactions. The remaining observation is merged with the anomalous observation \n",
    "# to create a test set. \n",
    "\n",
    "train_feature = nor_obs.loc[0:200000, :]\n",
    "train_feature = train_feature.drop('Category', 1)\n",
    "Y_1 = nor_obs.loc[200000:, 'Category']\n",
    "Y_2 = ano_obs['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
